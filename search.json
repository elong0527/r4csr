[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R for Clinical Study Reports and Submission",
    "section": "",
    "text": "Welcome\nWelcome to R for Clinical Study Reports and Submission. Clinical study reports (CSR) are crucial components in clinical trial development. A CSR is an “integrated” full scientific report of an individual clinical trials.\nThe ICH E3: Structure and Content of Clinical Study Reports offers comprehensive instructions to sponsors on the creation of a CSR. This book is a clear and straightforward guide on using R to streamline the process of preparing CSRs. Additionally, it provides detailed guidance on the submission process to regulatory agencies. Whether you are a beginner or an experienced R programmer, this book is an indispensable asset in your clinical reporting toolkit.\nThis is a work-in-progress draft."
  },
  {
    "objectID": "index.html#events",
    "href": "index.html#events",
    "title": "R for Clinical Study Reports and Submission",
    "section": "Events",
    "text": "Events\n\n\n\n\n\nVenue\nType\nDate\nMaterials\n\n\n\n\nR/Pharma Conference\nWorkshop\n2021-10-28\nSlides\n\n\nChina-R Conference\nTalk\n2021-11-20\nSlides\n\n\nASA Princeton-Trenton Chapter\nShort course\n2021-12-02\nSlides\n\n\nGWU Biostatistics Center\nTalk\n2022-01-21\nSlides\n\n\nRStudio Pharma Meetup Series\nTalk\n2022-05-17\nSlides\n\n\nASA Biopharmaceutical Section Regulatory-Industry Statistics Workshop\nShort course\n2022-09-20\nSlides\n\n\nPSI Webinar Series: Showcasing R use in Pharma\nTalk\n2022-10-25\nSlides"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "R for Clinical Study Reports and Submission",
    "section": "License",
    "text": "License\nThis book is licensed to you under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License."
  },
  {
    "objectID": "preface.html#folder-structure",
    "href": "preface.html#folder-structure",
    "title": "Preface",
    "section": "Folder structure",
    "text": "Folder structure\nIn the development of clinical trials, it is necessary to create and manage source code for generating and delivering Study Data Tabulation Model (SDTM), Analysis Dataset Model (ADaM) datasets, as well as tables, listings, and figures (TLFs). This is particularly evident in Phase 3 trials, where numerous TLFs are needed for submission. To effectively handle the large number of programs involved in such endeavors, it is essential to establish a consistent and well-defined folder structure for managing the analysis and reporting (A&R) project of a clinical trial.\nTo streamline the organization of source code and documentation for a clinical trial A&R project, we suggest employing the R package folder structure. This folder structure is extensively utilized within the R community and is well-defined, often found in repositories like CRAN. By adopting this structure, you can benefit from a standardized and widely accepted framework for managing your A&R-related materials in an efficient and accessible manner.\nUsing the R package folder structure provides a consistent approach that simplifies communication among developers, both within and across organizations.\n\nFor newcomers to R development, creating R packages is an essential step when sharing their work with others. The R community offers a widely adopted folder structure accompanied by excellent tutorials and free tools.\nFor an experienced R developer, there is a minimal learning curve.\nFor an organization, adopting the R package folder structure simplifies the development of processes, tools, templates, and training. It enables the use of a unified folder structure for building and maintaining standardized tool and analysis projects.\n\nThe workflow around an R package can also improve the traceability and reproducibility of an analysis project (Marwick, Boettiger, and Mullen 2018).\nWe will revisit the folder structure topic when discussing project management for a clinical trial project.\nAdditionally, the R package folder structure is also recommended for developing Shiny apps, as discussed in Chapter 20 of the Mastering Shiny book and the Engineering Production-Grade Shiny Apps book."
  },
  {
    "objectID": "preface.html#in-this-book",
    "href": "preface.html#in-this-book",
    "title": "Preface",
    "section": "In this book",
    "text": "In this book\nThis book is designed for intermediate-level readers who possess knowledge in both R programming and clinical development. Each part of the book makes certain assumptions about the readers’ background:\n\nPart 1, titled “Delivering TLFs in CSR”, provides general information and examples on creating tables, listings, and figures. It assumes that readers are individual contributors to a clinical project with prior experience in R programming. Familiarity with data manipulation in R is expected. Some recommended references for this part include Hands-On Programming with R, R for Data Science, and Data Manipulation with R.\nPart 2, titled “Clinical trial project”, provides general information and examples on managing a clinical trial A&R project. It assumes that readers are project leads who have experience in R package development. Recommended references for this part include R Packages and the tidyverse style guide.\nPart 3, titled “eCTD submission package”, provides general information on preparing submission packages related to the CSR in the electronic Common Technical Document (eCTD) format. It assumes that readers are project leads of clinical projects who possess experience in R package development and submission."
  },
  {
    "objectID": "preface.html#philosophy",
    "href": "preface.html#philosophy",
    "title": "Preface",
    "section": "Philosophy",
    "text": "Philosophy\nWe share the same philosophy described in the introduction of the R Packages book (Wickham and Bryan 2023), which we quote below:\n\n“Anything that can be automated, should be automated.”\n“Do as little as possible by hand. Do as much as possible with functions.”"
  },
  {
    "objectID": "preface.html#authors-and-contributors",
    "href": "preface.html#authors-and-contributors",
    "title": "Preface",
    "section": "Authors and contributors",
    "text": "Authors and contributors\nThis document is a collaborative effort maintained by a community. As you read through it, you also have the opportunity to contribute and enhance its quality. Your input and involvement play a vital role in shaping the excellence of this document.\n\nAuthors: made significant contributions to at least one chapter, constituting the majority of the content.\nYilong Zhang, Nan Xiao, Keaven Anderson, Yalin Zhu\nContributors: contributed at least one commit to the source code.\nWe are grateful for all the improvements brought by these contributors (in chronological order): Yujie Zhao (@LittleBeannie), Aiming Yang, Steven Haesendonckx (@SHAESEN2), Howard Baek (@howardbaek), Xiaoxia Han (@echohan), Jie Wang (@ifendo).\n\n\n\n\n\nMarwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. “Packaging Data Analytical Work Reproducibly Using R (and Friends).” The American Statistician 72 (1): 80–88.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. R Packages. O’Reilly Media, Inc."
  },
  {
    "objectID": "tlf-overview.html#background",
    "href": "tlf-overview.html#background",
    "title": "1  Overview",
    "section": "1.1 Background",
    "text": "1.1 Background\nIn clinical trials, a critical step is to submit trial results to regulatory agencies. Electronic Common Technical Document (eCTD) has become a worldwide regulatory submission standard format. For example, the United States Food and Drug Administration (US FDA) requires new drug applications and biologics license applications must be submitted using the eCTD format. The Clinical Data Interchange Standards Consortium (CDISC) provides a pilot project following ICH E3 guidance.\nWithin eCTD, clinical study reports (CSRs) are located at module 5. ICH E3 guidance provides a compilation of the structure and content of clinical study reports.\nA typical CSR contains full details on the methods and results of an individual clinical study. In support of the statistical analysis, a large number of tables, listings, and figures are incorporated into the main text and appendices. In the CDISC pilot project, an example CSR is also provided. If you are interested in more examples of clinical study reports, you can go to the European Medicines Agency (EMA) clinical data website.\nBuilding CSRs is teamwork between clinicians, medical writers, statisticians, statistical programmers, and other relevant specialists such as experts on biomarkers. Here, we focus on the work and deliverables completed by statisticians and statistical programmers. In an organization, they commonly work together to define, develop, validate and deliver tables, listings, and figures (TLFs) required for a CSR to summarize the efficacy and/or safety of the pharmaceutical product. Microsoft Word is widely used to prepare CSR in the pharmaceutical industry. Therefore, .rtf, .doc, .docx are commonly used formats in their deliverables.\nIn this chapter, our focus is to illustrate how to create tables, listings, and figures (TLFs) in RTF format that is commonly used in a CSR. The examples are in compliance with the FDA’s Portable Document Format (PDF) Specifications.\n\n\n\n\n\n\nNote\n\n\n\nFDA’s PDF specification is a general reference. Each organization can define more specific TLF format requirements that can be different from the examples in this book."
  },
  {
    "objectID": "tlf-overview.html#structure-and-content",
    "href": "tlf-overview.html#structure-and-content",
    "title": "1  Overview",
    "section": "1.2 Structure and content",
    "text": "1.2 Structure and content\nIn the rest of this chapter, we are following the ICH E3 guidance on the structure and content of clinical study reports.\nIn a CSR, most of TLFs are located in\n\nSection 10: Study participants\nSection 11: Efficacy evaluation\nSection 12: Safety evaluation\nSection 14: Tables, listings, and figures referrals but not included in the text\nSection 16: Appendices"
  },
  {
    "objectID": "tlf-overview.html#datasets",
    "href": "tlf-overview.html#datasets",
    "title": "1  Overview",
    "section": "1.3 Datasets",
    "text": "1.3 Datasets\nWe used publicly available CDISC pilot study data located in the CDISC GitHub repository.\nFor simplicity, we have downloaded all these datasets into the data-adam/ folder of this project and converted them from the .xpt format to the .sas7bdat format.\nThe dataset structure follows CDISC Analysis Data Model (ADaM)."
  },
  {
    "objectID": "tlf-overview.html#tools",
    "href": "tlf-overview.html#tools",
    "title": "1  Overview",
    "section": "1.4 Tools",
    "text": "1.4 Tools\nIn this part, we mainly use the R packages below to illustrate how to deliver TLFs in a CSR.\n\ntidyverse: prepare datasets ready for reporting.\nr2rtf: create RTF outputs\n\n\n\n\n\n\n\nNote\n\n\n\nThere are other R packages to create TLFs in ASCII, RTF and Word format. For example, rtables, huxtable, pharmaRTF, gt, officer, flextable etc. Here we focus on r2rtf to illustrate the concept. Readers are encouraged to explore other R packages to find the proper tools to fit your purpose.\n\n\n\n1.4.1 tidyverse\ntidyverse is a collection of R packages to simplify the workflow to manipulate, visualize and analyze data in R. Those R packages share the tidy tools manifesto and are easy to use for interactive data analysis.\nPosit provided outstanding cheatsheets and tutorials for tidyverse.\nThere are also books to introduce tidyverse. We assume the reader have experience in using tidyverse in this book.\n\nThe tidyverse cookbook\nR for Data Science\n\n\n\n1.4.2 r2rtf\nr2rtf is an R package to create production-ready tables and figures in RTF format. This R package is designed to\n\nprovide simple “verb” functions that correspond to each component of a table, to help you translate a data frame to a table in an RTF file;\nenable pipes (%&gt;%);\nfocus on the table format only. Data manipulation and analysis shall be handled by other R packages (e.g., tidyverse).\n\nBefore creating an RTF table, we need to\n\nfigure out the table layout;\nsplit the layout into small tasks in the form of a computer program;\nexecute the program.\n\nWe provide a brief introduction of r2rtf and show how to transfer data frames into table, listing, and figures (TLFs).\nOther extended examples and features are covered on the r2rtf package website.\nTo explore the basic RTF generation verbs in r2rtf, we will use the dataset r2rtf_adae saved in the r2rtf package. This dataset contains adverse events (AEs) information from a clinical trial.\nWe will begin by loading the packages:\n\nlibrary(dplyr) # Manipulate data\nlibrary(tidyr) # Manipulate data\nlibrary(r2rtf) # Reporting in RTF format\n\nBelow is the meaning of relevant variables. More information can be found on the help page of the dataset (?r2rtf_adae)\nIn this example, we consider three variables:\n\nUSUBJID: Unique Subject Identifier\nTRTA: Actual Treatment\nAEDECOD: Dictionary-Derived Term\n\n\nr2rtf_adae %&gt;%\n  select(USUBJID, TRTA, AEDECOD) %&gt;%\n  head(4)\n#&gt;       USUBJID    TRTA                   AEDECOD\n#&gt; 1 01-701-1015 Placebo APPLICATION SITE ERYTHEMA\n#&gt; 2 01-701-1015 Placebo APPLICATION SITE PRURITUS\n#&gt; 3 01-701-1015 Placebo                 DIARRHOEA\n#&gt; 4 01-701-1023 Placebo                  ERYTHEMA\n\ndplyr and tidyr packages within tidyverse are used for data manipulation to create a data frame that contains all the information we want to add in an RTF table.\n\ntbl &lt;- r2rtf_adae %&gt;%\n  count(TRTA, AEDECOD) %&gt;%\n  pivot_wider(names_from = TRTA, values_from = n, values_fill = 0)\n\ntbl %&gt;% head(4)\n#&gt; # A tibble: 4 × 4\n#&gt;   AEDECOD        Placebo `Xanomeline High Dose` `Xanomeline Low Dose`\n#&gt;   &lt;chr&gt;            &lt;int&gt;                  &lt;int&gt;                 &lt;int&gt;\n#&gt; 1 ABDOMINAL PAIN       1                      2                     3\n#&gt; 2 AGITATION            2                      1                     2\n#&gt; 3 ALOPECIA             1                      0                     0\n#&gt; 4 ANXIETY              2                      0                     4\n\nNow we have a dataset tbl in preparing the final RTF table.\nr2rtf aims to provide one function for each type of table layout. Commonly used verbs include:\n\nrtf_page(): RTF page information\nrtf_title(): RTF title information\nrtf_colheader(): RTF column header information\nrtf_body(): RTF table body information\nrtf_footnote(): RTF footnote information\nrtf_source(): RTF data source information\n\nAll these verbs are designed to enable the usage of pipes (%&gt;%). A full list of all functions can be found in the r2rtf package function reference manual.\nA minimal example below illustrates how to combine verbs using pipes to create an RTF table.\n\nrtf_body() is used to define table body layout.\nrtf_encode() transfers table layout information into RTF syntax.\nwrite_rtf() save RTF encoding into a file with file extension .rtf\n\n\nhead(tbl) %&gt;%\n  rtf_body() %&gt;% # Step 1 Add table attributes\n  rtf_encode() %&gt;% # Step 2 Convert attributes to RTF encode\n  write_rtf(\"tlf/intro-ae1.rtf\") # Step 3 Write to a .rtf file\n\n\n\n\n\n\n\n\n\n\nIf we want to adjust the width of each column to provide more space to the first column, this can be achieved by updating the col_rel_width argument in the rtf_body() function.\nIn this example, the input of col_rel_width is a vector with the same length for the number of columns. This argument defines the relative width of each column within a pre-defined total column width.\nIn this example, the defined relative width is 3:2:2:2. Only the ratio of col_rel_width is used. Therefore it is equivalent to use col_rel_width = c(6, 4, 4, 4) or col_rel_width = c(1.5, 1, 1, 1).\n\nhead(tbl) %&gt;%\n  rtf_body(col_rel_width = c(3, 2, 2, 2)) %&gt;%\n  # define relative width\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/intro-ae2.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn the previous example, we found the issue of a misaligned column header. We can fix the issue by using the rtf_colheader() function.\nIn rtf_colheader(), the colheader argument is used to provide the content of the column header. We use \"|\" to separate the columns.\nIn the example below, \"Adverse Events | Placebo | Xanomeline High Dose | Xanomeline Low Dose\" define a column header with 4 columns.\n\nhead(tbl) %&gt;%\n  rtf_colheader(\n    colheader = \"Adverse Events | Placebo | Xanomeline High Dose | Xanomeline Low Dose\",\n    col_rel_width = c(3, 2, 2, 2)\n  ) %&gt;%\n  rtf_body(col_rel_width = c(3, 2, 2, 2)) %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/intro-ae3.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn rtf_*() functions such as rtf_body(), rtf_footnote(), the text_justification argument is used to align text. Default is \"c\" for center justification. To vary text justification by column, use character vector with length of vector equals to number of columns displayed (e.g., c(\"c\", \"l\", \"r\")).\nAll possible inputs can be found in the table below.\n\nr2rtf:::justification()\n#&gt;   type      name rtf_code_text rtf_code_row\n#&gt; 1    l      left          \\\\ql       \\\\trql\n#&gt; 2    c    center          \\\\qc       \\\\trqc\n#&gt; 3    r     right          \\\\qr       \\\\trqr\n#&gt; 4    d   decimal          \\\\qj             \n#&gt; 5    j justified          \\\\qj\n\nBelow is an example to make the first column left-aligned and center-aligned for the rest.\n\nhead(tbl) %&gt;%\n  rtf_body(text_justification = c(\"l\", \"c\", \"c\", \"c\")) %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/intro-ae5.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn rtf_*() functions such as rtf_body(), rtf_footnote(), etc., border_left, border_right, border_top, and border_bottom control cell borders.\nIf we want to remove the top border of \"Adverse Events\" in the header, we can change the default value \"single\" to \"\" in the border_top argument, as shown below.\nr2rtf supports 26 different border types. The details can be found on the r2rtf package website.\nIn this example, we also demonstrate the possibility of adding multiple column headers.\n\nhead(tbl) %&gt;%\n  rtf_colheader(\n    colheader = \" | Treatment\",\n    col_rel_width = c(3, 6)\n  ) %&gt;%\n  rtf_colheader(\n    colheader = \"Adverse Events | Placebo | Xanomeline High Dose | Xanomeline Low Dose\",\n    border_top = c(\"\", \"single\", \"single\", \"single\"),\n    col_rel_width = c(3, 2, 2, 2)\n  ) %&gt;%\n  rtf_body(col_rel_width = c(3, 2, 2, 2)) %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/intro-ae7.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn the r2rtf R package get started page, there are more examples to illustrate how to customize\n\ntitle, subtitle\nfootnote, data source\nspecial character\netc.\n\nThose features will be introduced when we first use them in the rest of the chapters."
  },
  {
    "objectID": "tlf-disposition.html",
    "href": "tlf-disposition.html",
    "title": "2  Disposition",
    "section": "",
    "text": "Following ICH E3 guidance, a summary table needs to be provided to include all participants who entered the study in Section 10.1, Disposition of Participants.\nThe disposition of participants table reports the numbers of participants who were randomized, and who entered and completed each phase of the study. In addition, the reasons for all post-randomization discontinuations, grouped by treatment and by major reason (lost to follow-up, adverse event, poor compliance, etc.) are reported.\n\nlibrary(haven) # Read SAS data\nlibrary(dplyr) # Manipulate data\nlibrary(tidyr) # Manipulate data\nlibrary(r2rtf) # Reporting in RTF format\n\nIn this chapter, we show how to create a typical disposition table.\n\n\n\n\n\n\n\n\n\nThe first step is to read in the relevant datasets into R. For a disposition table, all the required information is saved in a Subject-level Analysis Dataset (ADSL). This dataset is provided in sas7bdat format, which is a SAS data format currently used in many clinical trial analysis and reporting. The haven package is able to read the dataset, while maintaining its attributes (e.g., variable labels).\n\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\n\nThe following variables are used in the preparation of a simplified disposition of participants table:\n\nUSUBJID: unique subject identifier\nTRT01P: planned treatment\nTRT01PN: planned treatment numeric encoding\nDISCONFL: discontinued from study flag\nDCREASCD: discontinued from study reason coded\n\n\nadsl %&gt;%\n  select(USUBJID, TRT01P, TRT01PN, DISCONFL, DCREASCD) %&gt;%\n  head(4)\n#&gt; # A tibble: 4 × 5\n#&gt;   USUBJID     TRT01P               TRT01PN DISCONFL DCREASCD        \n#&gt;   &lt;chr&gt;       &lt;chr&gt;                  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;           \n#&gt; 1 01-701-1015 Placebo                    0 \"\"       Completed       \n#&gt; 2 01-701-1023 Placebo                    0 \"Y\"      Adverse Event   \n#&gt; 3 01-701-1028 Xanomeline High Dose      81 \"\"       Completed       \n#&gt; 4 01-701-1033 Xanomeline Low Dose       54 \"Y\"      Sponsor Decision\n\nIn the code below, we calculate the number of participants in the analysis population by treatment arms.\n\nn_rand &lt;- adsl %&gt;%\n  group_by(TRT01PN) %&gt;%\n  summarize(n = n()) %&gt;%\n  pivot_wider(\n    names_from = TRT01PN,\n    names_prefix = \"n_\",\n    values_from = n\n  ) %&gt;%\n  mutate(row = \"Participants in population\")\n\nn_rand\n#&gt; # A tibble: 1 × 4\n#&gt;     n_0  n_54  n_81 row                       \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;                     \n#&gt; 1    86    84    84 Participants in population\n\n\nn_disc &lt;- adsl %&gt;%\n  group_by(TRT01PN) %&gt;%\n  summarize(\n    n = sum(DISCONFL == \"Y\"),\n    pct = formatC(n / n() * 100,\n      digits = 1, format = \"f\", width = 5\n    )\n  ) %&gt;%\n  pivot_wider(\n    names_from = TRT01PN,\n    values_from = c(n, pct)\n  ) %&gt;%\n  mutate(row = \"Discontinued\")\n\nn_disc\n#&gt; # A tibble: 1 × 7\n#&gt;     n_0  n_54  n_81 pct_0   pct_54  pct_81  row         \n#&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;       \n#&gt; 1    28    59    57 \" 32.6\" \" 70.2\" \" 67.9\" Discontinued\n\nIn the code below, we calculate the number and percentage of participants who completed/discontinued the study for different reasons by treatment arms.\n\nn_reason &lt;- adsl %&gt;%\n  group_by(TRT01PN) %&gt;%\n  mutate(n_total = n()) %&gt;%\n  group_by(TRT01PN, DCREASCD) %&gt;%\n  summarize(\n    n = n(),\n    pct = formatC(n / unique(n_total) * 100,\n      digits = 1, format = \"f\", width = 5\n    )\n  ) %&gt;%\n  pivot_wider(\n    id_cols = DCREASCD,\n    names_from = TRT01PN,\n    values_from = c(n, pct),\n    values_fill = list(n = 0, pct = \"  0.0\")\n  ) %&gt;%\n  rename(row = DCREASCD)\n\nn_reason\n#&gt; # A tibble: 10 × 7\n#&gt;    row                  n_0  n_54  n_81 pct_0   pct_54  pct_81 \n#&gt;    &lt;chr&gt;              &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt;  1 Adverse Event          8    44    40 \"  9.3\" \" 52.4\" \" 47.6\"\n#&gt;  2 Completed             58    25    27 \" 67.4\" \" 29.8\" \" 32.1\"\n#&gt;  3 Death                  2     1     0 \"  2.3\" \"  1.2\" \"  0.0\"\n#&gt;  4 I/E Not Met            1     0     2 \"  1.2\" \"  0.0\" \"  2.4\"\n#&gt;  5 Lack of Efficacy       3     0     1 \"  3.5\" \"  0.0\" \"  1.2\"\n#&gt;  6 Lost to Follow-up      1     1     0 \"  1.2\" \"  1.2\" \"  0.0\"\n#&gt;  7 Physician Decision     1     0     2 \"  1.2\" \"  0.0\" \"  2.4\"\n#&gt;  8 Protocol Violation     1     1     1 \"  1.2\" \"  1.2\" \"  1.2\"\n#&gt;  9 Sponsor Decision       2     2     3 \"  2.3\" \"  2.4\" \"  3.6\"\n#&gt; 10 Withdrew Consent       9    10     8 \" 10.5\" \" 11.9\" \"  9.5\"\n\nIn the code below, we calculate the number and percentage of participants who complete the study by treatment arms. We split n_reason because we want to customize the row order of the table.\n\nn_complete &lt;- n_reason %&gt;%\n  filter(row == \"Completed\")\n\nn_complete\n#&gt; # A tibble: 1 × 7\n#&gt;   row         n_0  n_54  n_81 pct_0   pct_54  pct_81 \n#&gt;   &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 Completed    58    25    27 \" 67.4\" \" 29.8\" \" 32.1\"\n\nIn the code below, we calculate the numbers and percentages of participants who discontinued the study for different reasons by treatment arms. For display purpose, paste0(\"    \", row) is used to add leading spaces to produce indentation in the final report.\n\nn_reason &lt;- n_reason %&gt;%\n  filter(row != \"Completed\") %&gt;%\n  mutate(row = paste0(\"    \", row))\n\nn_reason\n#&gt; # A tibble: 9 × 7\n#&gt;   row                        n_0  n_54  n_81 pct_0   pct_54  pct_81 \n#&gt;   &lt;chr&gt;                    &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 \"    Adverse Event\"          8    44    40 \"  9.3\" \" 52.4\" \" 47.6\"\n#&gt; 2 \"    Death\"                  2     1     0 \"  2.3\" \"  1.2\" \"  0.0\"\n#&gt; 3 \"    I/E Not Met\"            1     0     2 \"  1.2\" \"  0.0\" \"  2.4\"\n#&gt; 4 \"    Lack of Efficacy\"       3     0     1 \"  3.5\" \"  0.0\" \"  1.2\"\n#&gt; 5 \"    Lost to Follow-up\"      1     1     0 \"  1.2\" \"  1.2\" \"  0.0\"\n#&gt; 6 \"    Physician Decision\"     1     0     2 \"  1.2\" \"  0.0\" \"  2.4\"\n#&gt; 7 \"    Protocol Violation\"     1     1     1 \"  1.2\" \"  1.2\" \"  1.2\"\n#&gt; 8 \"    Sponsor Decision\"       2     2     3 \"  2.3\" \"  2.4\" \"  3.6\"\n#&gt; 9 \"    Withdrew Consent\"       9    10     8 \" 10.5\" \" 11.9\" \"  9.5\"\n\nNow we combine individual rows into one table for reporting purpose. tbl_disp is used as input for r2rtf to create final report.\n\ntbl_disp &lt;- bind_rows(n_rand, n_complete, n_disc, n_reason) %&gt;%\n  select(row, ends_with(c(\"_0\", \"_54\", \"_81\")))\n\ntbl_disp\n#&gt; # A tibble: 12 × 7\n#&gt;    row                            n_0 pct_0    n_54 pct_54   n_81 pct_81 \n#&gt;    &lt;chr&gt;                        &lt;int&gt; &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;   &lt;int&gt; &lt;chr&gt;  \n#&gt;  1 \"Participants in population\"    86  &lt;NA&gt;      84  &lt;NA&gt;      84  &lt;NA&gt;  \n#&gt;  2 \"Completed\"                     58 \" 67.4\"    25 \" 29.8\"    27 \" 32.1\"\n#&gt;  3 \"Discontinued\"                  28 \" 32.6\"    59 \" 70.2\"    57 \" 67.9\"\n#&gt;  4 \"    Adverse Event\"              8 \"  9.3\"    44 \" 52.4\"    40 \" 47.6\"\n#&gt;  5 \"    Death\"                      2 \"  2.3\"     1 \"  1.2\"     0 \"  0.0\"\n#&gt;  6 \"    I/E Not Met\"                1 \"  1.2\"     0 \"  0.0\"     2 \"  2.4\"\n#&gt;  7 \"    Lack of Efficacy\"           3 \"  3.5\"     0 \"  0.0\"     1 \"  1.2\"\n#&gt;  8 \"    Lost to Follow-up\"          1 \"  1.2\"     1 \"  1.2\"     0 \"  0.0\"\n#&gt;  9 \"    Physician Decision\"         1 \"  1.2\"     0 \"  0.0\"     2 \"  2.4\"\n#&gt; 10 \"    Protocol Violation\"         1 \"  1.2\"     1 \"  1.2\"     1 \"  1.2\"\n#&gt; 11 \"    Sponsor Decision\"           2 \"  2.3\"     2 \"  2.4\"     3 \"  3.6\"\n#&gt; 12 \"    Withdrew Consent\"           9 \" 10.5\"    10 \" 11.9\"     8 \"  9.5\"\n\nIn the below code, formatting of the final table is defined. Items that were not discussed in the previous sections, are highlighted below.\nThe rtf_title defines table title. We can provide a vector for the title argument. Each value is a separate line. The format can also be controlled by providing a vector input in text format.\n\ntbl_disp %&gt;%\n  # Table title\n  rtf_title(\"Disposition of Participants\") %&gt;%\n  # First row of column header\n  rtf_colheader(\" | Placebo | Xanomeline Low Dose| Xanomeline High Dose\",\n    col_rel_width = c(3, rep(2, 3))\n  ) %&gt;%\n  # Second row of column header\n  rtf_colheader(\" | n | (%) | n | (%) | n | (%)\",\n    col_rel_width = c(3, rep(c(0.7, 1.3), 3)),\n    border_top = c(\"\", rep(\"single\", 6)),\n    border_left = c(\"single\", rep(c(\"single\", \"\"), 3))\n  ) %&gt;%\n  # Table body\n  rtf_body(\n    col_rel_width = c(3, rep(c(0.7, 1.3), 3)),\n    text_justification = c(\"l\", rep(\"c\", 6)),\n    border_left = c(\"single\", rep(c(\"single\", \"\"), 3))\n  ) %&gt;%\n  # Encoding RTF syntax\n  rtf_encode() %&gt;%\n  # Save to a file\n  write_rtf(\"tlf/tbl_disp.rtf\")\n\n\n\n\n\n\n\n\n\n\nThe procedure to generate a disposition table can be summarized as follows:\n\nStep 1: Read subject level data (i.e., adsl) into R.\nStep 2: Count participants in the analysis population and name the dataset n_rand.\nStep 3: Calculate the number and percentage of participants who discontinued the study by treatment arm, and name the dataset n_disc.\nStep 4: Calculate the numbers and percentages of participants who discontinued the study for different reasons by treatment arm, and name the dataset n_reason.\nStep 5: Calculate the number and percentage of participants who completed the study by treatment arm, and name the dataset n_complete.\nStep 6: Bind n_rand, n_disc, n_reason, and n_complete by row.\nStep 7: Write the final table to RTF"
  },
  {
    "objectID": "tlf-population.html#helper-functions",
    "href": "tlf-population.html#helper-functions",
    "title": "3  Analysis population",
    "section": "3.1 Helper functions",
    "text": "3.1 Helper functions\nBefore we write the analysis code, let’s discuss the possibility of reusing R code by writing helper functions.\nAs discussed in R for data science, “You should consider writing a function whenever you’ve copied and pasted a block of code more than twice”.\nIn Chapter 2, there are a few repeating steps to:\n\nFormat the percentages using the formatC() function.\nCalculate the numbers and percentages by treatment arm.\n\nWe create two ad-hoc functions and use them to create the tables in the rest of this book.\nTo format numbers and percentages, we create a function called fmt_num(). It is a very simple function wrapping formatC().\n\nfmt_num &lt;- function(x, digits, width = digits + 4) {\n  formatC(\n    x,\n    digits = digits,\n    format = \"f\",\n    width = width\n  )\n}\n\nThe main reason to create the fmt_num() function is to enhance the readability of the analysis code.\nFor example, we can compare the two versions of code to format the percentage used in Chapter 2 and fmt_num().\n\nformatC(n / n() * 100,\n  digits = 1, format = \"f\", width = 5\n)\n\n\nfmt_num(n / n() * 100, digits = 1)\n\nTo calculate the numbers and percentages of participants by groups, we provide a simple (but not robust) wrapper function, count_by(), using the dplyr and tidyr package.\nThe function can be enhanced in multiple ways, but here we only focus on simplicity and readability. More details about writing R functions can be found in the STAT 545 course.\n\ncount_by &lt;- function(data, # Input data set\n                     grp, # Group variable\n                     var, # Analysis variable\n                     var_label = var, # Analysis variable label\n                     id = \"USUBJID\") { # Subject ID variable\n  data &lt;- data %&gt;% rename(grp = !!grp, var = !!var, id = !!id)\n\n  left_join(\n    count(data, grp, var),\n    count(data, grp, name = \"tot\"),\n    by = \"grp\",\n  ) %&gt;%\n    mutate(\n      pct = fmt_num(100 * n / tot, digits = 1),\n      n = fmt_num(n, digits = 0),\n      npct = paste0(n, \" (\", pct, \")\")\n    ) %&gt;%\n    pivot_wider(\n      id_cols = var,\n      names_from = grp,\n      values_from = c(n, pct, npct),\n      values_fill = list(n = \"0\", pct = fmt_num(0, digits = 0))\n    ) %&gt;%\n    mutate(var_label = var_label)\n}\n\nBy using the count_by() function, we can simplify the analysis code as below.\n\ncount_by(adsl, \"TRT01PN\", \"EFFFL\") %&gt;%\n  select(-ends_with(c(\"_54\", \"_81\")))\n#&gt; # A tibble: 2 × 5\n#&gt;   var   n_0    pct_0   npct_0         var_label\n#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;    \n#&gt; 1 N     \"   7\" \"  8.1\" \"   7 (  8.1)\" EFFFL    \n#&gt; 2 Y     \"  79\" \" 91.9\" \"  79 ( 91.9)\" EFFFL"
  },
  {
    "objectID": "tlf-population.html#analysis-code",
    "href": "tlf-population.html#analysis-code",
    "title": "3  Analysis population",
    "section": "3.2 Analysis code",
    "text": "3.2 Analysis code\nWith the helper function count_by, we can easily prepare a report dataset as\n\n# Derive a randomization flag\nadsl &lt;- adsl %&gt;% mutate(RANDFL = \"Y\")\n\npop &lt;- count_by(adsl, \"TRT01PN\", \"RANDFL\",\n  var_label = \"Participants in Population\"\n) %&gt;%\n  select(var_label, starts_with(\"n_\"))\n\n\npop1 &lt;- bind_rows(\n  count_by(adsl, \"TRT01PN\", \"ITTFL\",\n    var_label = \"Participants included in ITT population\"\n  ),\n  count_by(adsl, \"TRT01PN\", \"EFFFL\",\n    var_label = \"Participants included in efficacy population\"\n  ),\n  count_by(adsl, \"TRT01PN\", \"SAFFL\",\n    var_label = \"Participants included in safety population\"\n  )\n) %&gt;%\n  filter(var == \"Y\") %&gt;%\n  select(var_label, starts_with(\"npct_\"))\n\nNow we combine individual rows into one table for reporting purpose. tbl_pop is used as input for r2rtf to create the final report.\n\nnames(pop) &lt;- gsub(\"n_\", \"npct_\", names(pop))\ntbl_pop &lt;- bind_rows(pop, pop1)\n\ntbl_pop %&gt;% select(var_label, npct_0)\n#&gt; # A tibble: 4 × 2\n#&gt;   var_label                                    npct_0        \n#&gt;   &lt;chr&gt;                                        &lt;chr&gt;         \n#&gt; 1 Participants in Population                   \"  86\"        \n#&gt; 2 Participants included in ITT population      \"  86 (100.0)\"\n#&gt; 3 Participants included in efficacy population \"  79 ( 91.9)\"\n#&gt; 4 Participants included in safety population   \"  86 (100.0)\"\n\nWe define the format of the output using code below.\n\nrel_width &lt;- c(2, rep(1, 3))\ncolheader &lt;- \" | Placebo | Xanomeline line Low Dose| Xanomeline line High Dose\"\ntbl_pop %&gt;%\n  # Table title\n  rtf_title(\n    \"Summary of Analysis Sets\",\n    \"(All Participants Randomized)\"\n  ) %&gt;%\n  # First row of column header\n  rtf_colheader(colheader,\n    col_rel_width = rel_width\n  ) %&gt;%\n  # Second row of column header\n  rtf_colheader(\" | n (%) | n (%) | n (%)\",\n    border_top = \"\",\n    col_rel_width = rel_width\n  ) %&gt;%\n  # Table body\n  rtf_body(\n    col_rel_width = rel_width,\n    text_justification = c(\"l\", rep(\"c\", 3))\n  ) %&gt;%\n  # Encoding RTF syntax\n  rtf_encode() %&gt;%\n  # Save to a file\n  write_rtf(\"tlf/tbl_pop.rtf\")\n\n\n\n\n\n\n\n\n\n\nThe procedure to generate an analysis population table can be summarized as follows:\n\nStep 1: Read data (i.e., adsl) into R.\nStep 2: Bind the counts/percentages of the ITT population, the efficacy population, and the safety population by row using the count_by() function.\nStep 3: Format the output from Step 2 using r2rtf."
  },
  {
    "objectID": "tlf-baseline.html",
    "href": "tlf-baseline.html",
    "title": "4  Baseline characteristics",
    "section": "",
    "text": "Following ICH E3 guidance, we need to summarize critical demographic and baseline characteristics of the participants in Section 11.2, Demographic and Other Baseline Characteristics.\nIn this chapter, we illustrate how to create a simplified baseline characteristics table for a study.\n\n\n\n\n\n\n\n\n\nThere are many R packages that can efficiently summarize baseline information. The table1 R package is one of them.\n\nlibrary(table1)\nlibrary(r2rtf)\nlibrary(haven)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(tools)\n\nAs in previous chapters, we first read the adsl dataset that contains all the required information for the baseline characteristics table.\n\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\n\nFor simplicity, we only analyze SEX, AGE and, RACE in this example using the table1 R package. More details of the table1 R package can be found in the package vignettes.\nThe table1 R package directly creates an HTML report.\n\nana &lt;- adsl %&gt;%\n  mutate(\n    SEX = factor(SEX, c(\"F\", \"M\"), c(\"Female\", \"Male\")),\n    RACE = toTitleCase(tolower(RACE))\n  )\n\ntbl &lt;- table1(~ SEX + AGE + RACE | TRT01P, data = ana)\ntbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlacebo\n(N=86)\nXanomeline High Dose\n(N=84)\nXanomeline Low Dose\n(N=84)\nOverall\n(N=254)\n\n\n\n\nSEX\n\n\n\n\n\n\nFemale\n53 (61.6%)\n40 (47.6%)\n50 (59.5%)\n143 (56.3%)\n\n\nMale\n33 (38.4%)\n44 (52.4%)\n34 (40.5%)\n111 (43.7%)\n\n\nAge\n\n\n\n\n\n\nMean (SD)\n75.2 (8.59)\n74.4 (7.89)\n75.7 (8.29)\n75.1 (8.25)\n\n\nMedian [Min, Max]\n76.0 [52.0, 89.0]\n76.0 [56.0, 88.0]\n77.5 [51.0, 88.0]\n77.0 [51.0, 89.0]\n\n\nRACE\n\n\n\n\n\n\nBlack or African American\n8 (9.3%)\n9 (10.7%)\n6 (7.1%)\n23 (9.1%)\n\n\nWhite\n78 (90.7%)\n74 (88.1%)\n78 (92.9%)\n230 (90.6%)\n\n\nAmerican Indian or Alaska Native\n0 (0%)\n1 (1.2%)\n0 (0%)\n1 (0.4%)\n\n\n\n\n\n\n\nThe code below transfer the output into a dataframe that only contains ASCII characters recommended by regulatory agencies. tbl_base is used as input for r2rtf to create the final report.\n\ntbl_base &lt;- tbl %&gt;%\n  as.data.frame() %&gt;%\n  as_tibble() %&gt;%\n  mutate(across(\n    everything(),\n    ~ str_replace_all(.x, intToUtf8(160), \" \")\n  ))\n\n\nnames(tbl_base) &lt;- str_replace_all(names(tbl_base), intToUtf8(160), \" \")\ntbl_base\n#&gt; # A tibble: 11 × 5\n#&gt;    ` `              Placebo `Xanomeline High Dose` `Xanomeline Low Dose` Overall\n#&gt;    &lt;chr&gt;            &lt;chr&gt;   &lt;chr&gt;                  &lt;chr&gt;                 &lt;chr&gt;  \n#&gt;  1 \"\"               \"(N=86… \"(N=84)\"               \"(N=84)\"              \"(N=25…\n#&gt;  2 \"SEX\"            \"\"      \"\"                     \"\"                    \"\"     \n#&gt;  3 \"  Female\"       \"53 (6… \"40 (47.6%)\"           \"50 (59.5%)\"          \"143 (…\n#&gt;  4 \"  Male\"         \"33 (3… \"44 (52.4%)\"           \"34 (40.5%)\"          \"111 (…\n#&gt;  5 \"Age\"            \"\"      \"\"                     \"\"                    \"\"     \n#&gt;  6 \"  Mean (SD)\"    \"75.2 … \"74.4 (7.89)\"          \"75.7 (8.29)\"         \"75.1 …\n#&gt;  7 \"  Median [Min,… \"76.0 … \"76.0 [56.0, 88.0]\"    \"77.5 [51.0, 88.0]\"   \"77.0 …\n#&gt;  8 \"RACE\"           \"\"      \"\"                     \"\"                    \"\"     \n#&gt;  9 \"  Black or Afr… \"8 (9.… \"9 (10.7%)\"            \"6 (7.1%)\"            \"23 (9…\n#&gt; 10 \"  White\"        \"78 (9… \"74 (88.1%)\"           \"78 (92.9%)\"          \"230 (…\n#&gt; 11 \"  American Ind… \"0 (0%… \"1 (1.2%)\"             \"0 (0%)\"              \"1 (0.…\n\nWe define the format of the output. We highlight items that are not discussed in previous discussion.\ntext_indent_first and text_indent_left are used to control the indent space of text. They are helpful when you need to control the white space of a long phrase, “AMERICAN INDIAN OR ALASKA NATIVE” in the table provides an example.\n\ncolheader1 &lt;- paste(names(tbl_base), collapse = \"|\")\ncolheader2 &lt;- paste(tbl_base[1, ], collapse = \"|\")\nrel_width &lt;- c(2.5, rep(1, 4))\n\ntbl_base[-1, ] %&gt;%\n  rtf_title(\n    \"Baseline Characteristics of Participants\",\n    \"(All Participants Randomized)\"\n  ) %&gt;%\n  rtf_colheader(colheader1,\n    col_rel_width = rel_width\n  ) %&gt;%\n  rtf_colheader(colheader2,\n    border_top = \"\",\n    col_rel_width = rel_width\n  ) %&gt;%\n  rtf_body(\n    col_rel_width = rel_width,\n    text_justification = c(\"l\", rep(\"c\", 4)),\n    text_indent_first = -240,\n    text_indent_left = 180\n  ) %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_base.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the procedure to generate demographic and baseline characteristics table is summarized as follows:\n\nStep 1: Read the data set.\nStep 2: Use table1::table1() to get the baseline characteristics table.\nStep 3: Transfer the output from Step 2 into a data frame that only contains ASCII characters.\nStep 4: Define the format of the RTF table by using the R package r2rtf."
  },
  {
    "objectID": "tlf-efficacy-ancova.html#analysis-dataset",
    "href": "tlf-efficacy-ancova.html#analysis-dataset",
    "title": "5  Efficacy table",
    "section": "5.1 Analysis dataset",
    "text": "5.1 Analysis dataset\nTo prepare the analysis, both adsl and adlbc datasets are required.\n\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\nadlb &lt;- read_sas(\"data-adam/adlbc.sas7bdat\")\n\nFirst, both the population and the data in scope are selected. The analysis is done on the efficacy population, identified by EFFFL == \"Y\", and all records post baseline (AVISITN &gt;= 1) and on or before Week 24 (AVISITN &lt;= 24). Here the variable AVISITN is the numerical analysis visit. For example, if the analysis visit is recorded as “Baseline” (i.e., AVISIT = Baseline), AVISITN = 0; if the analysis visit is recorded as “Week 24” (i.e., AVISIT = Week 24), AVISITN = 24; if the analysis visit is blank, AVISITN is also blank. We will discuss these missing values in Section 6.4.\n\ngluc &lt;- adlb %&gt;%\n  left_join(adsl %&gt;% select(USUBJID, EFFFL), by = \"USUBJID\") %&gt;%\n  # PARAMCD is parameter code and here we focus on Glucose (mg/dL)\n  filter(EFFFL == \"Y\" & PARAMCD == \"GLUC\") %&gt;%\n  arrange(TRTPN) %&gt;%\n  mutate(TRTP = factor(TRTP, levels = unique(TRTP)))\n\nana &lt;- gluc %&gt;%\n  filter(AVISITN &gt; 0 & AVISITN &lt;= 24) %&gt;%\n  arrange(AVISITN) %&gt;%\n  mutate(AVISIT = factor(AVISIT, levels = unique(AVISIT)))\n\nBelow is the first few records of the analysis dataset.\n\nAVAL: analysis value\nBASE: baseline value\nCHG: change from baseline\n\n\nana %&gt;%\n  select(USUBJID, TRTPN, AVISIT, AVAL, BASE, CHG) %&gt;%\n  head(4)\n#&gt; # A tibble: 4 × 6\n#&gt;   USUBJID     TRTPN AVISIT              AVAL  BASE     CHG\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;fct&gt;              &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 01-701-1015     0 \"          Week 2\"  4.66  4.72 -0.0555\n#&gt; 2 01-701-1023     0 \"          Week 2\"  5.77  5.33  0.444 \n#&gt; 3 01-701-1047     0 \"          Week 2\"  5.55  5.55  0     \n#&gt; 4 01-701-1118     0 \"          Week 2\"  4.88  4.05  0.833"
  },
  {
    "objectID": "tlf-efficacy-ancova.html#helper-functions",
    "href": "tlf-efficacy-ancova.html#helper-functions",
    "title": "5  Efficacy table",
    "section": "5.2 Helper functions",
    "text": "5.2 Helper functions\nTo prepare the report, we create a few helper functions by using the fmt_num() function defined in Chapter 3.\n\nFormat estimators\n\n\nfmt_num &lt;- function(x, digits, width = digits + 4) {\n  formatC(\n    x,\n    digits = digits,\n    format = \"f\",\n    width = width\n  )\n}\n\n\nfmt_est &lt;- function(.mean,\n                    .sd,\n                    digits = c(1, 2)) {\n  .mean &lt;- fmt_num(.mean, digits[1], width = digits[1] + 4)\n  .sd &lt;- fmt_num(.sd, digits[2], width = digits[2] + 3)\n  paste0(.mean, \" (\", .sd, \")\")\n}\n\n\nFormat confidence interval\n\n\nfmt_ci &lt;- function(.est,\n                   .lower,\n                   .upper,\n                   digits = 2,\n                   width = digits + 3) {\n  .est &lt;- fmt_num(.est, digits, width)\n  .lower &lt;- fmt_num(.lower, digits, width)\n  .upper &lt;- fmt_num(.upper, digits, width)\n  paste0(.est, \" (\", .lower, \",\", .upper, \")\")\n}\n\n\nFormat p-value\n\n\nfmt_pval &lt;- function(.p, digits = 3) {\n  scale &lt;- 10^(-1 * digits)\n  p_scale &lt;- paste0(\"&lt;\", digits)\n  if_else(.p &lt; scale, p_scale, fmt_num(.p, digits = digits))\n}"
  },
  {
    "objectID": "tlf-efficacy-ancova.html#summary-of-observed-data",
    "href": "tlf-efficacy-ancova.html#summary-of-observed-data",
    "title": "5  Efficacy table",
    "section": "5.3 Summary of observed data",
    "text": "5.3 Summary of observed data\nFirst the observed data at Baseline and Week 24 are summarized using code below:\n\nt11 &lt;- gluc %&gt;%\n  filter(AVISITN %in% c(0, 24)) %&gt;%\n  group_by(TRTPN, TRTP, AVISITN) %&gt;%\n  summarise(\n    n = n(),\n    mean_sd = fmt_est(mean(AVAL), sd(AVAL))\n  ) %&gt;%\n  pivot_wider(\n    id_cols = c(TRTP, TRTPN),\n    names_from = AVISITN,\n    values_from = c(n, mean_sd)\n  )\n\nt11\n#&gt; # A tibble: 3 × 6\n#&gt; # Groups:   TRTPN, TRTP [3]\n#&gt;   TRTP                 TRTPN   n_0  n_24 mean_sd_0       mean_sd_24     \n#&gt;   &lt;fct&gt;                &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;          \n#&gt; 1 Placebo                  0    79    57 \"  5.7 ( 2.23)\" \"  5.7 ( 1.83)\"\n#&gt; 2 Xanomeline Low Dose     54    79    26 \"  5.4 ( 0.95)\" \"  5.7 ( 1.26)\"\n#&gt; 3 Xanomeline High Dose    81    74    30 \"  5.4 ( 1.37)\" \"  6.0 ( 1.92)\"\n\nAlso the observed change from baseline glucose at Week 24 is summarized using code below:\n\nt12 &lt;- gluc %&gt;%\n  filter(AVISITN %in% 24) %&gt;%\n  group_by(TRTPN, AVISITN) %&gt;%\n  summarise(\n    n_chg = n(),\n    mean_chg = fmt_est(\n      mean(CHG, na.rm = TRUE),\n      sd(CHG, na.rm = TRUE)\n    )\n  )\n\nt12\n#&gt; # A tibble: 3 × 4\n#&gt; # Groups:   TRTPN [3]\n#&gt;   TRTPN AVISITN n_chg mean_chg       \n#&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;          \n#&gt; 1     0      24    57 \" -0.1 ( 2.68)\"\n#&gt; 2    54      24    26 \"  0.2 ( 0.82)\"\n#&gt; 3    81      24    30 \"  0.5 ( 1.94)\""
  },
  {
    "objectID": "tlf-efficacy-ancova.html#missing-data-imputation",
    "href": "tlf-efficacy-ancova.html#missing-data-imputation",
    "title": "5  Efficacy table",
    "section": "5.4 Missing data imputation",
    "text": "5.4 Missing data imputation\nIn clinical trials, missing data is inevitable. In this study, there are missing values in glucose data.\n\ncount(ana, AVISIT)\n#&gt; # A tibble: 8 × 2\n#&gt;   AVISIT                 n\n#&gt;   &lt;fct&gt;              &lt;int&gt;\n#&gt; 1 \"          Week 2\"   229\n#&gt; 2 \"          Week 4\"   211\n#&gt; 3 \"          Week 6\"   197\n#&gt; 4 \"          Week 8\"   187\n#&gt; 5 \"         Week 12\"   167\n#&gt; 6 \"         Week 16\"   147\n#&gt; 7 \"         Week 20\"   126\n#&gt; 8 \"         Week 24\"   113\n\nFor simplicity and illustration purpose, we use the last observation carried forward (LOCF) approach to handle missing data. LOCF approach is a single imputation approach that is not recommended in real application. Interested readers can find more discussion on missing data approaches in the book: The Prevention and Treatment of Missing Data in Clinical Trials.\n\nana_locf &lt;- ana %&gt;%\n  group_by(USUBJID) %&gt;%\n  mutate(locf = AVISITN == max(AVISITN)) %&gt;%\n  filter(locf)"
  },
  {
    "objectID": "tlf-efficacy-ancova.html#ancova-model",
    "href": "tlf-efficacy-ancova.html#ancova-model",
    "title": "5  Efficacy table",
    "section": "5.5 ANCOVA model",
    "text": "5.5 ANCOVA model\nThe imputed data is analyzed using the ANCOVA model with treatment and baseline glucose as covariates.\n\nfit &lt;- lm(CHG ~ BASE + TRTP, data = ana_locf)\nsummary(fit)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = CHG ~ BASE + TRTP, data = ana_locf)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -6.9907 -0.7195 -0.2367  0.2422  7.0754 \n#&gt; \n#&gt; Coefficients:\n#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)               3.00836    0.39392   7.637 6.23e-13 ***\n#&gt; BASE                     -0.53483    0.06267  -8.535 2.06e-15 ***\n#&gt; TRTPXanomeline Low Dose  -0.17367    0.24421  -0.711    0.478    \n#&gt; TRTPXanomeline High Dose  0.32983    0.24846   1.327    0.186    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.527 on 226 degrees of freedom\n#&gt;   (2 observations deleted due to missingness)\n#&gt; Multiple R-squared:  0.2567, Adjusted R-squared:  0.2468 \n#&gt; F-statistic: 26.01 on 3 and 226 DF,  p-value: 1.714e-14\n\nThe emmeans R package is used to obtain within and between group least square (LS) mean\n\nfit_within &lt;- emmeans(fit, \"TRTP\")\nfit_within\n#&gt;  TRTP                  emmean    SE  df lower.CL upper.CL\n#&gt;  Placebo               0.0676 0.172 226   -0.272    0.407\n#&gt;  Xanomeline Low Dose  -0.1060 0.173 226   -0.447    0.235\n#&gt;  Xanomeline High Dose  0.3975 0.179 226    0.045    0.750\n#&gt; \n#&gt; Confidence level used: 0.95\n\n\nt13 &lt;- fit_within %&gt;%\n  as_tibble() %&gt;%\n  mutate(ls = fmt_ci(emmean, lower.CL, upper.CL)) %&gt;%\n  select(TRTP, ls)\nt13\n#&gt; # A tibble: 3 × 2\n#&gt;   TRTP                 ls                   \n#&gt;   &lt;fct&gt;                &lt;chr&gt;                \n#&gt; 1 Placebo              \" 0.07 (-0.27, 0.41)\"\n#&gt; 2 Xanomeline Low Dose  \"-0.11 (-0.45, 0.23)\"\n#&gt; 3 Xanomeline High Dose \" 0.40 ( 0.05, 0.75)\"\n\n\nfit_between &lt;- pairs(fit_within, reverse = TRUE)\nfit_between\n#&gt;  contrast                                   estimate    SE  df t.ratio p.value\n#&gt;  Xanomeline Low Dose - Placebo                -0.174 0.244 226  -0.711  0.7571\n#&gt;  Xanomeline High Dose - Placebo                0.330 0.248 226   1.327  0.3814\n#&gt;  Xanomeline High Dose - Xanomeline Low Dose    0.504 0.249 226   2.024  0.1087\n#&gt; \n#&gt; P value adjustment: tukey method for comparing a family of 3 estimates\n\n\nt2 &lt;- fit_between %&gt;%\n  as_tibble() %&gt;%\n  mutate(\n    ls = fmt_ci(\n      estimate,\n      estimate - 1.96 * SE,\n      estimate + 1.96 * SE\n    ),\n    p = fmt_pval(p.value)\n  ) %&gt;%\n  filter(stringr::str_detect(contrast, \"- Placebo\")) %&gt;%\n  select(contrast, ls, p)\n\nt2\n#&gt; # A tibble: 2 × 3\n#&gt;   contrast                       ls                    p        \n#&gt;   &lt;chr&gt;                          &lt;chr&gt;                 &lt;chr&gt;    \n#&gt; 1 Xanomeline Low Dose - Placebo  \"-0.17 (-0.65, 0.30)\" \"  0.757\"\n#&gt; 2 Xanomeline High Dose - Placebo \" 0.33 (-0.16, 0.82)\" \"  0.381\""
  },
  {
    "objectID": "tlf-efficacy-ancova.html#reporting",
    "href": "tlf-efficacy-ancova.html#reporting",
    "title": "5  Efficacy table",
    "section": "5.6 Reporting",
    "text": "5.6 Reporting\nt11, t12 and t13 are combined to get the first part of the report table\n\nt1 &lt;- cbind(\n  t11 %&gt;% ungroup() %&gt;% select(TRTP, ends_with(\"0\"), ends_with(\"24\")),\n  t12 %&gt;% ungroup() %&gt;% select(ends_with(\"chg\")),\n  t13 %&gt;% ungroup() %&gt;% select(ls)\n)\nt1\n#&gt;                   TRTP n_0     mean_sd_0 n_24    mean_sd_24 n_chg      mean_chg\n#&gt; 1              Placebo  79   5.7 ( 2.23)   57   5.7 ( 1.83)    57  -0.1 ( 2.68)\n#&gt; 2  Xanomeline Low Dose  79   5.4 ( 0.95)   26   5.7 ( 1.26)    26   0.2 ( 0.82)\n#&gt; 3 Xanomeline High Dose  74   5.4 ( 1.37)   30   6.0 ( 1.92)    30   0.5 ( 1.94)\n#&gt;                    ls\n#&gt; 1  0.07 (-0.27, 0.41)\n#&gt; 2 -0.11 (-0.45, 0.23)\n#&gt; 3  0.40 ( 0.05, 0.75)\n\nThen r2rtf is used to prepare the table format for t1. We also highlight how to handle special characters in this example.\nSpecial characters ^ and _ are used to define superscript and subscript of text. And {} is to define the part that will be impacted. For example, {^a} provides a superscript a for footnote notation. r2rtf also supports most LaTeX characters. Examples can be found on the r2rtf get started page. The text_convert argument in r2rtf_*() functions controls whether to convert special characters.\n\nt1_rtf &lt;- t1 %&gt;%\n  data.frame() %&gt;%\n  rtf_title(c(\n    \"ANCOVA of Change from Baseline Glucose (mmol/L) at Week 24\",\n    \"LOCF\",\n    \"Efficacy Analysis Population\"\n  )) %&gt;%\n  rtf_colheader(\"| Baseline | Week 24 | Change from Baseline\",\n    col_rel_width = c(2.5, 2, 2, 4)\n  ) %&gt;%\n  rtf_colheader(\n    paste(\n      \"Treatment |\",\n      paste0(rep(\"N | Mean (SD) | \", 3), collapse = \"\"),\n      \"LS Mean (95% CI){^a}\"\n    ),\n    col_rel_width = c(2.5, rep(c(0.5, 1.5), 3), 2)\n  ) %&gt;%\n  rtf_body(\n    text_justification = c(\"l\", rep(\"c\", 7)),\n    col_rel_width = c(2.5, rep(c(0.5, 1.5), 3), 2)\n  ) %&gt;%\n  rtf_footnote(c(\n    \"{^a}Based on an ANCOVA model after adjusting baseline value. LOCF approach is used to impute missing values.\",\n    \"ANCOVA = Analysis of Covariance, LOCF = Last Observation Carried Forward\",\n    \"CI = Confidence Interval, LS = Least Squares, SD = Standard Deviation\"\n  ))\n\nt1_rtf %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_eff1.rtf\")\n\n\n\n\n\n\n\n\n\n\nWe also use r2rtf to prepare the table format for t2\n\nt2_rtf &lt;- t2 %&gt;%\n  data.frame() %&gt;%\n  rtf_colheader(\"Pairwise Comparison | Difference in LS Mean (95% CI){^a} | p-Value\",\n    col_rel_width = c(4.5, 4, 2)\n  ) %&gt;%\n  rtf_body(\n    text_justification = c(\"l\", \"c\", \"c\"),\n    col_rel_width = c(4.5, 4, 2)\n  )\n\nt2_rtf %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_eff2.rtf\")\n\n\n\n\n\n\n\n\n\n\nFinally, we combine the two parts to get the final table using r2rtf. This is achieved by providing a list of t1_rtf and t2_rtf as input for rtf_encode.\n\nlist(t1_rtf, t2_rtf) %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_eff.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the procedure to generate the above efficacy results table is summarized as follows.\n\nStep 1: Read the data (i.e., adsl and adlb) into R.\nStep 2: Define the analysis dataset. In this example, we define two analysis datasets. The first dataset is the efficacy population (gluc). The second dataset is the collection of all records post baseline and on or before week 24 (ana).\nStep 3: Impute the missing values. In this example, we name the ana dataset after imputation as ana_locf.\nStep 4: Calculate the mean and standard derivation of efficacy endpoint (i.e., gluc), and then format it into an RTF table.\nStep 5: Calculate the pairwise comparison by ANCOVA model, and then format it into an RTF table.\nStep 6: Combine the outputs from steps 4 and 5 by rows."
  },
  {
    "objectID": "tlf-efficacy-km.html#analysis-dataset",
    "href": "tlf-efficacy-km.html#analysis-dataset",
    "title": "6  Efficacy figure",
    "section": "6.1 Analysis dataset",
    "text": "6.1 Analysis dataset\nTo prepare the analysis, the adtte dataset is required.\n\nadtte &lt;- read_sas(\"data-adam/adtte.sas7bdat\")\n\nFirst, to prepare the analysis ready data, filter all records for the efficacy endpoint of time to event of interest (TTDE) using PARAMCD (or PARAM, PRAMN), then select the survival analysis related variables:\n\nTRTP: treatment arm (using corresponding numeric code TRTAN to re-order the levels, “Placebo” will be the reference level)\nAVAL: time-to-event analysis value\nCNSR: event (censoring) status\n\n\nadtte_ttde &lt;- adtte %&gt;%\n  filter(PARAMCD == \"TTDE\") %&gt;%\n  select(TRTP, TRTAN, AVAL, CNSR) %&gt;%\n  mutate(\n    TRTP = forcats::fct_reorder(TRTP, TRTAN), # Recorder levels\n    AVAL_m = AVAL / 30.4367 # Convert Day to Month\n  )"
  },
  {
    "objectID": "tlf-efficacy-km.html#create-kaplan-meier-curve",
    "href": "tlf-efficacy-km.html#create-kaplan-meier-curve",
    "title": "6  Efficacy figure",
    "section": "6.2 Create Kaplan-Meier curve",
    "text": "6.2 Create Kaplan-Meier curve\nThe survival package is used to obtain the K-M estimate.\n\n# Fit survival model, convert the time value from Days to Month\nfit &lt;- survfit(Surv(AVAL_m, 1 - CNSR) ~ TRTP, data = adtte_ttde)\n\nWe save the simplified K-M plot into a .png file using code below.\n\n# Save as a PNG file\npng(\n  file = \"tlf/fig_km.png\",\n  width = 3000,\n  height = 2000,\n  res = 300\n)\n\nplot(\n  fit,\n  xlab = \"Time in Months\",\n  ylab = \"Survival probability\",\n  mark.time = TRUE,\n  lwd = 2,\n  col = c(2, 3, 4),\n  lty = c(1, 2, 3)\n)\n\ndev.off()\n\nNow, we can use the r2rtf package to create a formatted RTF figure. More details can be found on the r2rtf website.\n\n# Create RTF figure\nrtf_read_figure(\"tlf/fig_km.png\") %&gt;% # Read the PNG file from the file path\n  rtf_title(\n    \"Kaplan-Meier Plot for Time to First Dermatologic Event by Treatment Group\",\n    \"All Participants\"\n  ) %&gt;% # Add title or subtitle\n  rtf_footnote(\"footnote\") %&gt;% # Add footnote\n  rtf_source(\"[datasource: adam-adtte]\") %&gt;% # Add data source\n  rtf_figure(fig_width = 6, fig_height = 4) %&gt;% # Set proportional figure size to the original PNG figure size\n  rtf_encode(doc_type = \"figure\") %&gt;% # Encode figure as rtf\n  write_rtf(file = \"tlf/tlf_km.rtf\")\n\n\n\n\n\n\n\n\n\n\nIn conclusion, the steps to create a K-M plot are as follows.\n\nStep 1: Read the data adtte into R.\nStep 2: Define the analysis-ready dataset. In this example, we define the analysis dataset for the TTDE endpoint adtte_ttde.\nStep 3: Save figures into png files based on required analysis specification.\nStep 4: Create RTF output using the r2rtf package."
  },
  {
    "objectID": "tlf-ae-summary.html",
    "href": "tlf-ae-summary.html",
    "title": "7  AE summary",
    "section": "",
    "text": "Following ICH E3 guidance, we summarize number of participants that were included in each safety analysis in Section 12.2, Adverse Events (AEs).\n\nlibrary(haven) # Read SAS data\nlibrary(dplyr) # Manipulate data\nlibrary(tidyr) # Manipulate data\nlibrary(r2rtf) # Reporting in RTF format\n\nIn this chapter, we illustrate how to summarize AEs information for a study.\n\n\n\n\n\n\n\n\n\nThe data used to summarize AE information is in adsl and adae datasets.\n\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\nadae &lt;- read_sas(\"data-adam/adae.sas7bdat\")\n\nWe first summarize participants in population by treatment arm.\n\npop &lt;- adsl %&gt;%\n  filter(SAFFL == \"Y\") %&gt;%\n  rename(TRTAN = TRT01AN) %&gt;%\n  count(TRTAN, name = \"tot\")\n\npop\n#&gt; # A tibble: 3 × 2\n#&gt;   TRTAN   tot\n#&gt;   &lt;dbl&gt; &lt;int&gt;\n#&gt; 1     0    86\n#&gt; 2    54    84\n#&gt; 3    81    84\n\nWe transform the data to simplify the analysis of each required AE criteria of interest.\n\nWith one or more adverse events\nWith drug-related adverse events\nWith serious adverse events\nWith serious drug-related adverse events\nWho died\n\n\ntidy_ae &lt;- adae %&gt;%\n  mutate(\n    all = SAFFL == \"Y\",\n    drug = AEREL %in% c(\"POSSIBLE\", \"PROBABLE\"),\n    ser = AESER == \"Y\",\n    drug_ser = drug & ser,\n    die = AEOUT == \"FATAL\"\n  ) %&gt;%\n  select(USUBJID, TRTAN, all, drug, ser, drug_ser, die) %&gt;%\n  pivot_longer(cols = c(all, drug, ser, drug_ser, die))\n\ntidy_ae %&gt;% head(4)\n#&gt; # A tibble: 4 × 4\n#&gt;   USUBJID     TRTAN name     value\n#&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;    &lt;lgl&gt;\n#&gt; 1 01-701-1015     0 all      TRUE \n#&gt; 2 01-701-1015     0 drug     TRUE \n#&gt; 3 01-701-1015     0 ser      FALSE\n#&gt; 4 01-701-1015     0 drug_ser FALSE\n\nWe summarize the number and percentage of participants who meet each AE criteria.\n\nfmt_num &lt;- function(x, digits, width = digits + 4) {\n  formatC(\n    x,\n    digits = digits,\n    format = \"f\",\n    width = width\n  )\n}\n\n\nana &lt;- tidy_ae %&gt;%\n  filter(value == TRUE) %&gt;%\n  group_by(TRTAN, name) %&gt;%\n  summarise(n = n_distinct(USUBJID)) %&gt;%\n  left_join(pop, by = \"TRTAN\") %&gt;%\n  mutate(\n    pct = fmt_num(n / tot * 100, digits = 1),\n    n = fmt_num(n, digits = 0),\n    pct = paste0(\"(\", pct, \")\")\n  )\n\nana %&gt;% head(4)\n#&gt; # A tibble: 4 × 5\n#&gt; # Groups:   TRTAN [2]\n#&gt;   TRTAN name  n        tot pct    \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;int&gt; &lt;chr&gt;  \n#&gt; 1     0 all   \"  69\"    86 ( 80.2)\n#&gt; 2     0 die   \"   2\"    86 (  2.3)\n#&gt; 3     0 drug  \"  44\"    86 ( 51.2)\n#&gt; 4    54 all   \"  77\"    84 ( 91.7)\n\nWe prepare reporting-ready dataset for each AE group.\n\nt_ae &lt;- ana %&gt;%\n  pivot_wider(\n    id_cols = \"name\",\n    names_from = TRTAN,\n    values_from = c(n, pct),\n    values_fill = list(\n      n = \"   0\",\n      pct = \"(  0.0)\"\n    )\n  )\n\nt_ae &lt;- t_ae %&gt;%\n  mutate(name = factor(\n    name,\n    c(\"all\", \"drug\", \"ser\", \"drug_ser\", \"die\"),\n    c(\n      \"With one or more adverse events\",\n      \"With drug-related adverse events\",\n      \"With serious adverse events\",\n      \"With serious drug-related adverse events\",\n      \"Who died\"\n    )\n  )) %&gt;%\n  arrange(name)\n\nWe prepare reporting-ready dataset for the analysis population.\n\nt_pop &lt;- pop %&gt;%\n  mutate(\n    name = \"Participants in population\",\n    tot = fmt_num(tot, digits = 0)\n  ) %&gt;%\n  pivot_wider(\n    id_cols = name,\n    names_from = TRTAN,\n    names_prefix = \"n_\",\n    values_from = tot\n  )\n\nt_pop\n#&gt; # A tibble: 1 × 4\n#&gt;   name                       n_0    n_54   n_81  \n#&gt;   &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 Participants in population \"  86\" \"  84\" \"  84\"\n\nThe final report data is saved in tbl_ae_summary.\n\ntbl_ae_summary &lt;- bind_rows(t_pop, t_ae) %&gt;%\n  select(name, ends_with(\"_0\"), ends_with(\"_54\"), ends_with(\"_81\"))\n\ntbl_ae_summary\n#&gt; # A tibble: 6 × 7\n#&gt;   name                                     n_0   pct_0 n_54  pct_54 n_81  pct_81\n#&gt;   &lt;chr&gt;                                    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt; \n#&gt; 1 Participants in population               \"  8… &lt;NA&gt;  \"  8… &lt;NA&gt;   \"  8… &lt;NA&gt;  \n#&gt; 2 With one or more adverse events          \"  6… ( 80… \"  7… ( 91.… \"  7… ( 94.…\n#&gt; 3 With drug-related adverse events         \"  4… ( 51… \"  7… ( 86.… \"  7… ( 83.…\n#&gt; 4 With serious adverse events              \"   … (  0… \"   … (  1.… \"   … (  2.…\n#&gt; 5 With serious drug-related adverse events \"   … (  0… \"   … (  1.… \"   … (  1.…\n#&gt; 6 Who died                                 \"   … (  2… \"   … (  1.… \"   … (  0.…\n\nWe define the format of the output using code below:\n\ntbl_ae_summary %&gt;%\n  rtf_title(\n    \"Analysis of Adverse Event Summary\",\n    \"(Safety Analysis Population)\"\n  ) %&gt;%\n  rtf_colheader(\" | Placebo | Xanomeline Low Dose| Xanomeline High Dose\",\n    col_rel_width = c(3.5, rep(2, 3))\n  ) %&gt;%\n  rtf_colheader(\" | n | (%) | n | (%) | n | (%)\",\n    col_rel_width = c(3.5, rep(c(0.7, 1.3), 3)),\n    border_top = c(\"\", rep(\"single\", 6)),\n    border_left = c(\"single\", rep(c(\"single\", \"\"), 3))\n  ) %&gt;%\n  rtf_body(\n    col_rel_width = c(3.5, rep(c(0.7, 1.3), 3)),\n    text_justification = c(\"l\", rep(\"c\", 6)),\n    border_left = c(\"single\", rep(c(\"single\", \"\"), 3))\n  ) %&gt;%\n  rtf_footnote(\"Every subject is counted a single time for each applicable row and column.\") %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_ae_summary.rtf\")\n\n\n\n\n\n\n\n\n\n\nThe procedure to generate an AE summary table can be summarized as follows:\n\nStep 1: Read data (i.e., adae and adsl) into R.\nStep 2: Summarize participants in population by treatment arm, and name the dataset as t_pop.\nStep 3: Summarize participants in population by required AE criteria of interest, and name the dataset as t_ae.\nStep 4: Row-wise combine t_pop and t_ae and format it by using r2rtf."
  },
  {
    "objectID": "tlf-ae-specific.html",
    "href": "tlf-ae-specific.html",
    "title": "8  Specific AE",
    "section": "",
    "text": "Following ICH E3 guidance, we need to summarize number of participants for each specific AE in Section 12.2, Adverse Events (AEs).\n\nlibrary(haven) # Read SAS data\nlibrary(dplyr) # Manipulate data\nlibrary(tidyr) # Manipulate data\nlibrary(r2rtf) # Reporting in RTF format\n\nIn this chapter, we illustrate how to summarize simplified specific AE information for a study.\n\n\n\n\n\n\n\n\n\nThe data used to summarize AE information is in adsl and adae datasets.\n\nadsl &lt;- read_sas(\"data-adam/adsl.sas7bdat\")\nadae &lt;- read_sas(\"data-adam/adae.sas7bdat\")\n\nFor illustration purpose, we only provide counts in the simplified table. The percentage of participants for each AE can be calculated as shown in Chapter 7.\nHere, we focus on the analysis script for two advanced features for a table layout.\n\ngroup content: AE can be summarized in multiple nested layers. (e.g., by system organ class (SOC, AESOC) and specific AE term (AEDECOD))\npagenization: there are many AE terms that can not be covered in one page. Column headers and SOC information need to be repeated on every page.\n\nIn the code below, we count the number of participants in each AE term by SOC and treatment arm, and we create a new variable order and set it as 0. The variable order can help with the data manipulation later.\n\nfmt_num &lt;- function(x, digits, width = digits + 4) {\n  formatC(\n    x,\n    digits = digits,\n    format = \"f\",\n    width = width\n  )\n}\n\n\nana &lt;- adae %&gt;%\n  mutate(\n    AESOC = tools::toTitleCase(tolower(AESOC)),\n    AEDECOD = tools::toTitleCase(tolower(AEDECOD))\n  )\n\nt1 &lt;- ana %&gt;%\n  group_by(TRTAN, AESOC) %&gt;%\n  summarise(n = fmt_num(n_distinct(USUBJID), digits = 0)) %&gt;%\n  mutate(AEDECOD = AESOC, order = 0)\n\nt1 %&gt;% head(4)\n#&gt; # A tibble: 4 × 5\n#&gt; # Groups:   TRTAN [1]\n#&gt;   TRTAN AESOC                       n      AEDECOD                     order\n#&gt;   &lt;dbl&gt; &lt;chr&gt;                       &lt;chr&gt;  &lt;chr&gt;                       &lt;dbl&gt;\n#&gt; 1     0 Cardiac Disorders           \"  13\" Cardiac Disorders               0\n#&gt; 2     0 Ear and Labyrinth Disorders \"   1\" Ear and Labyrinth Disorders     0\n#&gt; 3     0 Eye Disorders               \"   4\" Eye Disorders                   0\n#&gt; 4     0 Gastrointestinal Disorders  \"  17\" Gastrointestinal Disorders      0\n\nIn the code below, we count the number of subjects in each AE term by SOC, AE term, and treatment arm. Here we also create a new variable order and set it as 1.\n\nt2 &lt;- ana %&gt;%\n  group_by(TRTAN, AESOC, AEDECOD) %&gt;%\n  summarise(n = fmt_num(n_distinct(USUBJID), digits = 0)) %&gt;%\n  mutate(order = 1)\n\nt2 %&gt;% head(4)\n#&gt; # A tibble: 4 × 5\n#&gt; # Groups:   TRTAN, AESOC [1]\n#&gt;   TRTAN AESOC             AEDECOD                              n      order\n#&gt;   &lt;dbl&gt; &lt;chr&gt;             &lt;chr&gt;                                &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1     0 Cardiac Disorders Atrial Fibrillation                  \"   1\"     1\n#&gt; 2     0 Cardiac Disorders Atrial Hypertrophy                   \"   1\"     1\n#&gt; 3     0 Cardiac Disorders Atrioventricular Block First Degree  \"   1\"     1\n#&gt; 4     0 Cardiac Disorders Atrioventricular Block Second Degree \"   2\"     1\n\nWe prepare reporting data for AE information using code below:\n\nt_ae &lt;- bind_rows(t1, t2) %&gt;%\n  pivot_wider(\n    id_cols = c(AESOC, order, AEDECOD),\n    names_from = TRTAN,\n    names_prefix = \"n_\",\n    values_from = n,\n    values_fill = fmt_num(0, digits = 0)\n  ) %&gt;%\n  arrange(AESOC, order, AEDECOD) %&gt;%\n  select(AESOC, AEDECOD, starts_with(\"n\"))\n\nt_ae %&gt;% head(4)\n#&gt; # A tibble: 4 × 5\n#&gt;   AESOC             AEDECOD             n_0    n_54   n_81  \n#&gt;   &lt;chr&gt;             &lt;chr&gt;               &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 Cardiac Disorders Cardiac Disorders   \"  13\" \"  13\" \"  18\"\n#&gt; 2 Cardiac Disorders Atrial Fibrillation \"   1\" \"   1\" \"   3\"\n#&gt; 3 Cardiac Disorders Atrial Flutter      \"   0\" \"   1\" \"   1\"\n#&gt; 4 Cardiac Disorders Atrial Hypertrophy  \"   1\" \"   0\" \"   0\"\n\nWe prepare reporting data for analysis population using code below:\n\ncount_by &lt;- function(data, # Input data set\n                     grp, # Group variable\n                     var, # Analysis variable\n                     var_label = var, # Analysis variable label\n                     id = \"USUBJID\") { # Subject ID variable\n  data &lt;- data %&gt;% rename(grp = !!grp, var = !!var, id = !!id)\n\n  left_join(\n    count(data, grp, var),\n    count(data, grp, name = \"tot\"),\n    by = \"grp\",\n  ) %&gt;%\n    mutate(\n      pct = fmt_num(100 * n / tot, digits = 1),\n      n = fmt_num(n, digits = 0),\n      npct = paste0(n, \" (\", pct, \")\")\n    ) %&gt;%\n    pivot_wider(\n      id_cols = var,\n      names_from = grp,\n      values_from = c(n, pct, npct),\n      values_fill = list(n = \"0\", pct = fmt_num(0, digits = 0))\n    ) %&gt;%\n    mutate(var_label = var_label)\n}\n\n\nt_pop &lt;- adsl %&gt;%\n  filter(SAFFL == \"Y\") %&gt;%\n  count_by(\"TRT01AN\", \"SAFFL\",\n    var_label = \"Participants in population\"\n  ) %&gt;%\n  mutate(\n    AESOC = \"pop\",\n    AEDECOD = var_label\n  ) %&gt;%\n  select(AESOC, AEDECOD, starts_with(\"n_\"))\n\nt_pop\n#&gt; # A tibble: 1 × 5\n#&gt;   AESOC AEDECOD                    n_0    n_54   n_81  \n#&gt;   &lt;chr&gt; &lt;chr&gt;                      &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 pop   Participants in population \"  86\" \"  84\" \"  84\"\n\nThe final report data is saved in tbl_ae_spec. We also add a blank row between population and AE information in the reporting table.\n\ntbl_ae_spec &lt;- bind_rows(\n  t_pop,\n  data.frame(AESOC = \"pop\"),\n  t_ae\n) %&gt;%\n  mutate(AEDECOD = ifelse(AEDECOD == AESOC,\n    AEDECOD, paste0(\"  \", AEDECOD)\n  ))\n\ntbl_ae_spec %&gt;% head(4)\n#&gt; # A tibble: 4 × 5\n#&gt;   AESOC             AEDECOD                        n_0    n_54   n_81  \n#&gt;   &lt;chr&gt;             &lt;chr&gt;                          &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt; \n#&gt; 1 pop               \"  Participants in population\" \"  86\" \"  84\" \"  84\"\n#&gt; 2 pop                &lt;NA&gt;                           &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt; \n#&gt; 3 Cardiac Disorders \"Cardiac Disorders\"            \"  13\" \"  13\" \"  18\"\n#&gt; 4 Cardiac Disorders \"  Atrial Fibrillation\"        \"   1\" \"   1\" \"   3\"\n\nWe define the format of the output as below:\nTo obtain the nested layout, we use the page_by argument in the rtf_body function. By defining page_by=\"AESOC\", r2rtf recognizes the variable as a group indicator.\nAfter setting pageby_row = \"first_row\", the first row is displayed as group header. If a group of information is broken into multiple pages, the group header row is repeated on each page by default.\nWe can also customize the text format by providing a matrix that has the same dimension as the input dataset (i.e., tbl_ae_spec). In the code below, we illustrate how to display bold text for group headers to highlight the nested structure of the table layout.\n\nn_row &lt;- nrow(tbl_ae_spec)\nn_col &lt;- ncol(tbl_ae_spec)\nid &lt;- tbl_ae_spec$AESOC == tbl_ae_spec$AEDECOD\nid &lt;- ifelse(is.na(id), FALSE, id)\n\ntext_format &lt;- ifelse(id, \"b\", \"\")\n\n\ntbl_ae_spec %&gt;%\n  rtf_title(\n    \"Analysis of Participants With Specific Adverse Events\",\n    \"(Safety Analysis Population)\"\n  ) %&gt;%\n  rtf_colheader(\" | Placebo | Xanomeline Low Dose| Xanomeline High Dose\",\n    col_rel_width = c(3, rep(1, 3))\n  ) %&gt;%\n  rtf_colheader(\" | n |  n | n \",\n    border_top = \"\",\n    border_bottom = \"single\",\n    col_rel_width = c(3, rep(1, 3))\n  ) %&gt;%\n  rtf_body(\n    col_rel_width = c(1, 3, rep(1, 3)),\n    text_justification = c(\"l\", \"l\", rep(\"c\", 3)),\n    text_format = matrix(text_format, nrow = n_row, ncol = n_col),\n    page_by = \"AESOC\",\n    pageby_row = \"first_row\"\n  ) %&gt;%\n  rtf_footnote(\"Every subject is counted a single time for each applicable row and column.\") %&gt;%\n  rtf_encode() %&gt;%\n  write_rtf(\"tlf/tlf_spec_ae.rtf\")\n\n\n\n\n\n\n\n\n\n\nMore discussion on page_by, group_by and subline_by features can be found on the r2rtf package website.\nThe procedure to generate a baseline characteristics table can be summarized as follows:\n\nStep 1: Read data (i.e., adae and adsl) into R.\nStep 2: Count the number of participants by SOC and treatment arm (rows with bold text) and save into t1.\nStep 3: Count the number of participants in each AE term by SOC, AE term, and treatment arm (rows without bold text) and save into t2.\nStep 4: Bind t1 and t2 by row into t_ae.\nStep 5: Count the number of participants in each arm as t_pop.\nStep 6: Row-wise combine t_pop and t_ae into tbl_ae_spec.\nStep 7: Format the output by using r2rtf."
  },
  {
    "objectID": "tlf-assemble.html#combine-rtf-source-code",
    "href": "tlf-assemble.html#combine-rtf-source-code",
    "title": "9  Assemble TLFs",
    "section": "9.1 Combine RTF Source Code",
    "text": "9.1 Combine RTF Source Code\n\n\n\n\n\n\nNote\n\n\n\nThe code below requires r2rtf version &gt;= 1.0.0.\n\n\nThe r2rtf::assemble_rtf() function allows the user to combine RTF source code in individual files into one larger RTF file.\n\n\n\n\n\n\nCaution\n\n\n\nOne limitation of combining RTF source code is that we are not able to specify the page orientation of each TLF in the combined document.\n\n\n\nr2rtf::assemble_rtf(\n  input = tlf_path,\n  output = \"tlf/rtf-combine.rtf\"\n)"
  },
  {
    "objectID": "tlf-assemble.html#using-toggle-fields",
    "href": "tlf-assemble.html#using-toggle-fields",
    "title": "9  Assemble TLFs",
    "section": "9.2 Using Toggle Fields",
    "text": "9.2 Using Toggle Fields\nMicrosoft Word uses toggle fields to embed files into one Word document. The approach is a dynamic link between files by providing the absolute file path.\n\n\n\n\n\n\nTip\n\n\n\nThere is a slight learning curve on how toggle fields work in Microsoft Word. After you become familiar with the workflow, toggle fields can extend your capability to manage a large number of TLFs in RTF format.\n\n\nThe assemble_docx() function allows you to create a .docx file with toggle fields as below. One benefit is to control the page direction of each TLF as below.\n\nr2rtf::assemble_docx(\n  tlf_path,\n  output = \"tlf/rtf-combine-toggle.docx\",\n  landscape = c(FALSE, FALSE, TRUE)\n)\n\nAfter opening the generated .docx file, you will see a blank file because the file only contains fields with hyperlinks.\nBy using Alt + F9 to display the fields and you will see information similar to the screenshot below.\n\n\n\n\n\nUsing Alt + F9 to display fields\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nA typical error message is that system can not find the file if you only provide a relative path. Please double-check that the correct absolute file path is in the INCLUDETEXT field.\n\n\nTo test the toggle field, you can right-click an INCLUDETEXT filed and click Update Field.\nIf it works, you can see a table similar to the snapshot below by using Alt + F9. It is a shortcut to change between results and field display mode.\n\n\n\n\n\nUpdate fields\n\n\n\n\nNow you can update all toggle fields to display all TLFs by selecting all fields (Ctrl + A), then press F9. We suggest testing one toggle field before updating all of them.\nAs the .docx file contain dynamic links, you can keep updating the TLFs if you need to refresh content in individual RTF files by selecting all fields (Ctrl + A), then press F9.\n\n\n\n\n\n\nTip\n\n\n\nIf you modify table content in the combined .docx file, you may get a weird table layout if you update all fields within a toggle field. To resolve the issue, please remove all \\* MERGEFORMAT in the filed mode using Alt + F9 before updating all toggle fields.\n\n\nAfter the combined TLF is ready for delivery, you can also unlink toggle fields to save table contents, because the absolute path may only work for some. To unlink toggle fields, you can select all fields (Ctrl + A), then press Ctrl + Shift + F9."
  },
  {
    "objectID": "project-overview.html",
    "href": "project-overview.html",
    "title": "10  Overview",
    "section": "",
    "text": "In a late-stage clinical trial, the number of A&R deliverables can easily be in the hundreds. For an organization, it is common to have multiple ongoing clinical trials in a clinical program.\nTo deliver the A&R results of a clinical trial project, it is teamwork that typically requires collaborations from both statisticians and programmers. In this part, let’s consider how to organize a clinical trial project as an A&R lead.\nChapter 11 will discuss how to organize source code, documents, and deliverables in an A&R clinical project. We recommend using the R package folder structure.\nChapter 12 will discuss a process or system development lifecycle to manage the A&R of a clinical project. We recommend following an agile management approach to define, develop, validate, and deliver work."
  },
  {
    "objectID": "project-folder.html#sec-consistency",
    "href": "project-folder.html#sec-consistency",
    "title": "11  Project folder",
    "section": "11.1 Consistency",
    "text": "11.1 Consistency\nFor consistency, a well-defined folder structure with potential templates ensures project teams organize the A&R work consistently across multiple projects. Consistent folder structure also reduces communication costs between study team members and enhances the transparency of projects.\nIn this book, we refer to an R package as a project-specific R package if the purpose of an R package is to organize analysis scripts for a clinical project.\nWe refer to an R package as a standard R package if the purpose of an R package is to share commonly used R functions to be hosted in a code repository such as CRAN.\nBelow is minimal sufficient folders and files for a project-specific R package based on the R package folder structure.\n\n*.Rproj: RStudio project file used to open RStudio project.\nDESCRIPTION: Metadata for a package including authors, license, dependencies, etc.\nR/: Project-specific R functions.\nvignettes/: Analysis scripts using R Markdown.\nman/: Manual of project-specific R functions.\n\nA general discussion of the R package folder structure can be found in Chapter 3 of the R Packages book (Wickham and Bryan 2023).\nWe demonstrate the idea using the esubdemo project.\nIn the esubdemo project, we saved all TLF generation scripts in previous chapters into the vignettes/ folder.\n\n\n\n\n\n\nNote\n\n\n\nUnder the vignettes/ folder, there are two folders: adam/ and tlf/. The adam/ folder contains ADaM datasets. The tlf/ folder contains output TLFs in RTF format. We put adam/ and tlf/ folders within the vignettes/ folder only for illustration purposes. In an actual A&R report, you may have a different location to save your input and output.\n\n\nvignettes\n├── data-adam\n├── tlf\n├── tlf-01-disposition.Rmd\n├── tlf-02-population.Rmd\n├── tlf-03-baseline.Rmd\n├── tlf-04-efficacy.Rmd\n├── tlf-05-ae-summary.Rmd\n└── tlf-06-ae-spec.Rmd\nWhile creating those analysis scripts, we also defined a few helper functions (e.g., fmt_num and count_by). Those functions are saved in the R/ folder.\nR/\n├── count_by.R\n└── fmt.R\nFor a clinical trial project, it is also important to provide proper documentation for those help functions. We use roxygen2 package to document functions. For example, the header below defines each variable in fmt_est. More details can be found in Chapter 16 of the R Packages book.\n\n#' Format point estimator\n#'\n#' @param .mean mean of an estimator.\n#' @param .sd sd of an estimator.\n#' @param digits number of digits for `.mean` and `.sd`.\n#'\n#' @export\nfmt_est &lt;- function(.mean, .sd, digits = c(1, 2)) {\n  .mean &lt;- fmt_num(.mean, digits[1], width = digits[1] + 4)\n  .sd &lt;- fmt_num(.sd, digits[2], width = digits[2] + 3)\n  paste0(.mean, \" (\", .sd, \")\")\n}\n\nThe roxygen2 documentation will be converted into standard R documentation format, and saved as .Rd files in the man/ folder. This step is automatically handled by devtools::document().\nman\n├── count_by.Rd\n├── fmt_ci.Rd\n├── fmt_est.Rd\n├── fmt_num.Rd\n└── fmt_pval.Rd\nThe man/ folder is used to save documentation automatically generated by roxygen2. A typical workflow is to add roxygen2 documentation before each function in the R/ folder. Then devtools::document() is used to generate all the documentation files in the man/ folder. More details can be found in Chapter 16 of the R Packages book."
  },
  {
    "objectID": "project-folder.html#sec-reproduce",
    "href": "project-folder.html#sec-reproduce",
    "title": "11  Project folder",
    "section": "11.2 Reproducibility",
    "text": "11.2 Reproducibility\nReproducibility of analysis is one of the most important aspects of regulatory deliverables. To ensure a successful reproduction, we need a controlled R environment, including the control of the R version and the R package versions. By using the R package folder structure and proper tools (e.g., renv, packrat), we illustrate how to achieve reproducibility for R and R package versions.\n\n\n\n\n\n\nTip\n\n\n\nThis is the same level of reproducibility in most SAS environments: https://support.sas.com/en/technical-support/services-policies.html#altos\n\n\n\n11.2.1 R version\nFirst, we introduce the control of the R version. In the esubdemo project, a reproducible environment is created when you open the esubdemo.Rproj from RStudio IDE. When we open the esubdemo project, RStudio IDE will execute the R code in .Rprofile automatically. So we can use .Rprofile to set up a reproducible environment. More details can be found in https://rstats.wtf/r-startup.html. After we open the esubdemo project, the code in .Rprofile will automatically check the current R version is the same as we defined in .Rprofile.\n\n# Set project R version\nR_version &lt;- \"4.1.1\"\n\nIf there is an R version mismatch, an error message is displayed as below.\nError: The current R version is not the same as the current project in R4.1.1\n\n\n\n\n\n\nCaution\n\n\n\n.Rprofile is only for project-specific R packages. A standard R package should not use .Rprofile.\n\n\n\n\n11.2.2 R package version\nNext, we introduce the control of the R package version, which is controlled in two layers. Firstly, we define a snapshot date in .Rprofile. The snapshot date allows us to freeze the source code repository.\n\n# set up snapshot date\nsnapshot &lt;- \"2021-08-06\"\n\n# set up repository based on the snapshot date\nrepos &lt;- paste0(\"https://packagemanager.posit.co/cran/\", snapshot)\n\n# define repo URL for project-specific package installation\noptions(repos = repos)\n\nWe can also define the package repository to be a specific snapshot date. For example, we used Posit Public Package Manager to define the snapshot date to be 2021-08-06. The snapshot date freezes the R package repository.\nIn other words, all R packages installed in this R project are based on the frozen R version at the snapshot date. Here it is 2021-08-06 by using the Posit Package Manager.\nThe information below will be displayed after a new R session is opened.\nCurrent project R package repository:\n    https://packagemanager.posit.co/cran/2021-08-06\n\n\n\n\n\n\nNote\n\n\n\nPosit Public Package Manager hosts daily CRAN snapshots for Mondays to Fridays of the week. Posit Package Manager, when deployed internally within an organization, provides a solution to host both publicly available and internally developed R packages.\n\n\nSecondly, we use renv to lock R package versions and save them in the renv.lock file. renv provides a robust and stable approach to managing R package versions for project-specific R packages. An introduction of renv can be found on its website.\n\nsource(\"renv/activate.R\")\n\nThe R code above in the .Rprofile initiates the renv running environment. As a user, you can use renv::init(), renv::snapshot(), and renv::restore() to initialize, save and restore R packages used for the current analysis project.\nIn the analysis project, the renv package will\n\ncreate a renv.lock file to save the state of package versions.\ncreate a renv/ folder to manage R packages for a project.\n\n\n\n\n\n\n\nCaution\n\n\n\nThe renv.lock file and renv/ folder are only for project-specific R package. A standard R package should not use renv.\n\n\nIn summary, the R package version is controlled in two layers.\n\nDefine a snapshot date in inst/startup.R.\nUsing renv to lock R versions within a project.\n\nIf the project is initiated properly, you should be able to see similar messages to inform how we control R package versions.\n* Project '~/esubdemo' loaded. [renv 0.14.0]\nOnce R packages have been properly installed, the system will use the R packages located in the search path defined based on the order of .libPaths(). The startup message also provided the R package search path.\nBelow R package path are searching in order to find installed R packages in this R session:\n    \"/home/zhanyilo/github-repo/esubdemo/renv/library/R-4.1/x86_64-pc-linux-gnu\"\n    \"/rtmp/RtmpT3ljoY/renv-system-library\"\n\n\n\n\n\n\nTip\n\n\n\nA cloud-based R environment (e.g., Posit Workbench) can enhance the reproducibility within an organization by using the same operating system, R version, and R package versions for an A&R project. More details can be found at https://environments.rstudio.com/.\n\n\n\n\n\n\n\n\nNote\n\n\n\nA container solution like Docker (Nüst et al. 2020) could further enhance the reproducibility across an organization at the operating system level but beyond the scope of this book.\n\n\nIn conclusion, to achieve reproducibility for a project-specific R package, a clinical project team can work under a controlled R environment in the same R version and R package versions defined by a repository snapshot date."
  },
  {
    "objectID": "project-folder.html#automation",
    "href": "project-folder.html#automation",
    "title": "11  Project folder",
    "section": "11.3 Automation",
    "text": "11.3 Automation\nBy using the R package folder structure, you will benefit from many outstanding tools to simplify and streamline your workflow.\nWe have learned a few functions in devtools to generate content automatically. Here is a list of tools that can enhance the workflow.\n\ndevtools: make package development easier.\n\nA good overview can be found in Chapter 2 of the R Packages book.\ndevtools::load_all(): load all functions in R/ folder and running environment.\ndevtools::document(): automatically create documentation using roxygen2.\ndevtools::check(): automatically perform compliance check as an R package.\ndevtools::build_site(): automatically run analysis scripts in batch and create a pkgdown website.\n\nusethis: automates repetitive tasks that arise during project setup and development.\ntestthat: streamline testing code.\n\nA discussion of using the testthat for an A&R project can be found in (Ginnaram et al. (2021)).\n\npkgdown: generate static HTML documentation website for an R package\n\nIt also allows you to run all analysis code in batch.\n\n\nYou may further automatically execute routines by leveraging CI/CD workflow. For example, the esubdemo project will rerun all required checks and build a pkgdown website by using Github Actions.\nAs the consistent folder is defined, it also becomes easier to create specific tools that fit the analysis and reporting purpose. Below are a few potential tools that can be helpful:\n\nCreate project template using RStudio project templates;\nAdd additional compliance checks for analysis and reporting;\nSave log files for running in batch."
  },
  {
    "objectID": "project-folder.html#compliance",
    "href": "project-folder.html#compliance",
    "title": "11  Project folder",
    "section": "11.4 Compliance",
    "text": "11.4 Compliance\nFor a regulatory deliverable, it is important to maintain compliance. With a consistent folder structure, we can define specific criteria for compliance. Some compliance criteria can be implemented within the automatically checking steps.\nFor an R package, there are already criteria to ensure R package integrity. More details can be found in Chapter 20 of the R Packages book.\n\n\n\n\nGinnaram, Madhusudhan, Simiao Ye, Yalin Zhu, and Yilong Zhang. 2021. “A Process to Validate Internal Developed R Package Under Regulatory Environment.” PharmaSUG.\n\n\nMarwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. “Packaging Data Analytical Work Reproducibly Using R (and Friends).” The American Statistician 72 (1): 80–88.\n\n\nNüst, Daniel, Dirk Eddelbuettel, Dom Bennett, Robrecht Cannoodt, Dav Clark, Gergely Daróczi, Mark Edmondson, et al. 2020. “The Rockerverse: Packages and Applications for Containerisation with R.” The R Journal 12 (1): 437–61.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. R Packages. O’Reilly Media, Inc.\n\n\nWu, Peikun, Uday Preetham Palukuru, Yiwen Luo, Sarad Nepal, and Yilong Zhang. 2021. “Analysis and Reporting in Regulated Clinical Trial Environment Using R.” PharmaSUG."
  },
  {
    "objectID": "project-management.html#setting-up-for-success",
    "href": "project-management.html#setting-up-for-success",
    "title": "12  Project management",
    "section": "12.1 Setting up for success",
    "text": "12.1 Setting up for success\nA clinical data analysis project is not unlike typical data analysis projects or software projects. Therefore, the conventional wisdom and tricks for managing a successful project are also applicable here. At the same time, clinical projects also have unique traits, such as high standards for planning, development, validation, and delivery under strict time constraints.\nAlthough many factors determine if a project can execute efficiently, we believe a few aspects are critical for long-term success, especially when managing clinical data analysis projects at scale.\n\n12.1.1 Work as a team\nAs a general principle, all the team members involved in a project should take basic training on project management and understand how to work as a development team. Fitzpatrick and Collins-Sussman (2012) provides some valuable tips on this topic. As always, setting a clear goal and following a system development lifecycle (SDLC) is essential.\n\n\n12.1.2 Design clean code architecture\nHaving a clean architecture design for your code improves the project’s robustness and flexibility for future changes. For example, we should understand how to separate business logic from other layers; know what should be created as reusable components and what should be written as one-off analysis scripts; write low coupling, high cohesion code, and so on. Martin, Grenning, and Brown (2018) offers some helpful insights on this topic.\n\n\n12.1.3 Set capability boundaries\nKnowing what you can do is essential. Create a core capabilities list for your team.\nSometimes, it is also critical to understand what not to do. For example, the hidden cost of integrating with external systems or involving other programming languages can be prohibitively high. Remember, a simple, robust solution is almost always preferable to a complex solution that requires high maintenance and constant attention.\n\n\n12.1.4 Contribute to the community\nEvery individual is limited in some way. The collective thinking from a community could benefit a project in the long term. When designing reusable components, make a plan to share with internal communities, or even better, with the open-source community."
  },
  {
    "objectID": "project-management.html#the-sdlc",
    "href": "project-management.html#the-sdlc",
    "title": "12  Project management",
    "section": "12.2 The SDLC",
    "text": "12.2 The SDLC\nFor A&R deliverables in clinical project development, a clearly defined process or system development lifecycle (SDLC) is crucial to ensure regulatory compliance.\nSDLC for the A&R deliverables can be defined in four stages.\n\nPlanning: a planning stage to define the scope of a project.\nDevelopment: a development stage to implement target deliverables.\nValidation: a validation stage to verify target deliverables.\nOperation: an operation stage to deliver work to stakeholders.\n\nImportantly, we should not consider SDLC as a linear process. For example, if the study team identifies a new requirement in a development or validation stage, the team should return to the planning stage to discuss and align the scope. An agile project management approach is suitable and recommended for an A&R clinical development project. The goal is to embrace an iterative approach that continuously improves target deliverables based on frequent stakeholder feedback.\nThere are many good tools to implement agile project management strategy, for example:\n\nGitHub project board\nJira"
  },
  {
    "objectID": "project-management.html#planning",
    "href": "project-management.html#planning",
    "title": "12  Project management",
    "section": "12.3 Planning",
    "text": "12.3 Planning\nThe planning stage is important in the SDLC lifecycle as the requirements for all A&R deliverables are gathered and documented.\nIn the planning stage, a project leader should identify all the deliverables, e.g., a list of tables, listings, and figures (TLFs). For each TLFs, the team should prepare the necessary specifications:\n\nmock-up tables\nvalidation level (e.g., independent review or double programming)\netc.\n\nThe project leader should also align work assignments with team members. The purpose is to answer the question of “who is doing what?”\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRequirement/Specification\n\n\nDeveloper Testing\n\n\nIndependent Testing\n\n\n\n\nProgram Name\n\n\nProgram Validation Category\n\n\nWho\n\n\nStatus\n\n\nWho\n\n\nStatus\n\n\nWho\n\n\nStatus\n\n\n\n\n\ncount_by\n3\nAlice\nC\nAlice\nC\nBob\nC\n\n\nfmt_ci\n3\nAlice\nC\nAlice\nC\nCarol\nC\n\n\nfmt_est\n3\nAlice\nC\nAlice\nC\nBob\nC\n\n\nfmt_num\n3\nAlice\nC\nAlice\nC\nCarol\nC\n\n\nfmt_pval\n3\nAlice\nC\nAlice\nC\nDave\nC\n\n\ntlf-01-disposition.Rmd\n3\nBob\nC\nBob\nC\nCarol\nI\n\n\ntlf-02-population.Rmd\n3\nCarol\nC\nCarol\nC\nDave\nI\n\n\ntlf-03-baseline.Rmd\n3\nDave\nC\nDave\nC\nBob\nC\n\n\ntlf-04-efficacy.Rmd\n3\nAlice\nC\nAlice\nC\nCarol\nC\n\n\ntlf-05-ae-summary.Rmd\n3\nBob\nC\nBob\nC\nDave\nI\n\n\ntlf-06-ae-spec.Rmd\n3\nCarol\nC\nCarol\nC\nBob\nC\n\n\n\n\n\n\n\n\n\nThe project lead should also set up a project folder, as discussed in Chapter 11. The project initiation can be simplified by creating an RStudio project template.\nTo enable reproducibility, the project leader should also review the startup file (i.e. .Rprofile discussed in Section 11.2) and define:\n\nR version\nRepository of R packages with a snapshot date\nProject package library path\netc.\n\n\n\n\n\n\n\nCaution\n\n\n\nAfter project initiation, modifying .Rprofile will be a risk for reproducibility and should be handled carefully if necessary."
  },
  {
    "objectID": "project-management.html#development",
    "href": "project-management.html#development",
    "title": "12  Project management",
    "section": "12.4 Development",
    "text": "12.4 Development\nAfter a project is initiated, the study team starts to develop TLFs based on pre-defined mock-up tables assigned to each team member.\nThe analysis code and relevant description can be saved in R Markdown files in the vignettes/ folder.\nThe use of R Markdown allows developers to assemble narrative text, code, and its comments in one place to simplify documentation. It would be helpful to create a template and define a name convention for all TLFs deliverables. For example, we can use the tlf_ prefix in the filename to indicate that the R Markdown file is for delivering TLFs. Multiple TLFs with similar designs can be included in one R Markdown file.\nFor example, in the esubdemo project, we have six R Markdown files to create TLFs.\nIf there are any project-specific R functions that need to be developed, the R functions can be placed in the R/ folder as discussed in Section 11.1."
  },
  {
    "objectID": "project-management.html#validation",
    "href": "project-management.html#validation",
    "title": "12  Project management",
    "section": "12.5 Validation",
    "text": "12.5 Validation\nValidation is a crucial stage to ensure the deliverables are accurate and consistent. After the development stage is completed, the project team needs to validate the deliverables, including R Markdown files for TLFs deliverables and project-specific R functions. The level of validation is determined at the define stage.\nIn an R package development, the validation or testing is completed under the test/ folder. The testthat R package can be used to streamline the validation process. More details of the testthat package for R package validation can be found in Chapter 12 of the R package book.\nIt is recommended to have a name convention to indicate the type of validation. For example, we can use test-developer-test, test-independent-test, test-double-programming to classify the validation type.\nIt is recommended to follow the same organization for files in testthat folder as R/ folder and vignettes/ folder. Every single file in the R/ folder and vignettes/ folder should have a testing file saved in the tests/testthat/ folder to validate the content.\nFor example, in esubdemo project, we can have a list of testing files below.\ntests/testthat\n├── test-independent-test-tlf-01-disposition.R\n├── test-independent-test-tlf-02-population.R\n├── test-independent-test-tlf-03-baseline.R\n├── test-independent-test-tlf-04-efficacy.R\n├── test-independent-test-tlf-05-ae-summary.R\n├── test-independent-test-tlf-06-ae-spec.R\n└── test-independent-test-fmt.R\nTo validate the content of a table, we can save the last datasets ready for table generation as a .Rdata file. A validator can reproduce the TLF and compare it with the original result saved in the .Rdata file. A test is passed when the results match. Customers can directly review the formatting of the TLFs by comparing them with the mock-up.\nTo validate a figure, we can use the snapshot testing strategy.\nAfter the validator completes the testing of project-specific functions and R Markdown files, the process to execute and report testing results is the same for a standard R package. The devtools::test() function automatically executes all testing cases and summarizes the testing results in a report.\nAfter completing the validation, the validator updates the status in a validation tracker. The project lead reviews the tracking sheet to make sure all required activities in the SDLC are completed, and the tracking sheet has been filled correctly. The deliverables are ready for customer review after all the validation steps are completed. Any changes to the output requested by customers are documented."
  },
  {
    "objectID": "project-management.html#operation",
    "href": "project-management.html#operation",
    "title": "12  Project management",
    "section": "12.6 Operation",
    "text": "12.6 Operation\nAfter completion of development and required validation of all A&R deliverables, the project lead runs compliance checks for a project-specific R package similar to other R packages. devtools::check() is a convenient way to run compliance checks or R CMD check. R CMD check is an automated check of the contents in the R package for frequently encountered issues before submission to CRAN. Since the project-specific R package is not submitted to CRAN, some checks can be customized and skipped in devtools::check(). The project lead should work with the study team to ensure all reported errors, warnings, and notes by devtools::check() are fixed.\nThe project lead can also use the R package pkgdown to build a complete website for a project-specific R package. The pkgdown website is a convenient way to run all analyses in batch and integrate outputs in a website, which comprehensively covers project-specific R functions, TLF generation programs, outputs and validation tracking information, etc. For example, in the esubdemo project, we created the pkgdown website at https://elong0527.github.io/esubdemo/.\nMany of the tasks in SDLC can be completed automatically. An organization can leverage CI/CD workflow to automatically enable those tasks, such as running testing cases and creating a pkgdown website. For example, in the esubdemo project, we set up GitHub Actions for it. This can be done by using usethis::use_github_action().\n\n\n\n\nFitzpatrick, Brian, and Ben Collins-Sussman. 2012. Team Geek: A Software Developer’s Guide to Working Well with Others. O’Reilly Media.\n\n\nMartin, Robert C, James Grenning, and Simon Brown. 2018. Clean Architecture: A Craftsman’s Guide to Software Structure and Design. Prentice Hall."
  },
  {
    "objectID": "submission-overview.html",
    "href": "submission-overview.html",
    "title": "13  Overview",
    "section": "",
    "text": "The electronic Common Technical Document (eCTD) is a standard format for the electronic submission of applications, amendments, supplements, and reports from the applicant to the regulator. The eCTD offers a solution to submit documents stored in a standard directory structure, with file integrity validation mechanisms in place.\nTo submit TLFs created by R to regulatory agencies, we should follow the spirit of the existing eCTD submission guidelines to prepare the deliverables, and provide the essential details in the relevant documents for review.\nThe goal of the following two chapters is to provide guidance to follow Section 4.1.2.10 of the FDA Study Data Technical Conformance Guide:\n\nSponsors should provide the software programs used to create all ADaM datasets and generate tables and figures associated with primary and secondary efficacy analyses. Furthermore, sponsors should submit software programs used to generate additional information included in Section 14 CLINICAL STUDIES of the Prescribing Information (PI)26 if applicable. The specific software utilized should be specified in the ADRG. The main purpose of requesting the submission of these programs is to understand the process by which the variables for the respective analyses were created and to confirm the analysis algorithms. Sponsors should submit software programs in ASCII text format; however, executable file extensions should not be used.\n\nChapter 14 will focus on preparing proprietary R packages and analysis code into proper formats for submission.\nChapter 15 will discuss the recommendations to make the R code running environment reproducible for dry run tests and reviews."
  },
  {
    "objectID": "submission-package.html#prerequisites",
    "href": "submission-package.html#prerequisites",
    "title": "14  Submission package",
    "section": "14.1 Prerequisites",
    "text": "14.1 Prerequisites\nThis chapter uses pkglite (Zhao et al. 2023) to convert R source packages into text files and back.\n\ninstall.packages(\"pkglite\")\n\nThe demo project (R package) we will prepare for submission is called esubdemo, which is available on GitHub. You can download or clone it:\ngit clone https://github.com/elong0527/esubdemo.git\nThe demo submission package (not to be confused with the R package above) is ectddemo, which is also available on GitHub. You can download or clone it:\ngit clone https://github.com/elong0527/ectddemo.git\nWe assume the paths to the two folders are esubdemo/ and ectddemo/ below."
  },
  {
    "objectID": "submission-package.html#the-whole-game",
    "href": "submission-package.html#the-whole-game",
    "title": "14  Submission package",
    "section": "14.2 The whole game",
    "text": "14.2 The whole game\nIn eCTD deliverable, the analysis datasets and source code are saved under the eCTD module 5 (clinical study reports) folder\nectddemo/m5/datasets/&lt;study&gt;/analysis/adam/\nThe files in two directories within the adam/ folder are critical for documenting analysis using R: datasets/ and programs/.\nectddemo/m5/datasets/ectddemo/analysis/adam/\n├── datasets\n│   ├── adae.xpt\n│   ├── ...\n│   ├── adrg.pdf\n│   ├── analysis-results-metadata.pdf\n│   ├── define.xml\n│   └── define2-0-0.xsl\n└── programs\n    ├── r0pkgs.txt\n    ├── tlf-01-disposition.txt\n    ├── tlf-02-population.txt\n    ├── tlf-03-baseline.txt\n    ├── tlf-04-efficacy.txt\n    ├── tlf-05-ae-summary.txt\n    └── tlf-06-ae-spec.txt\nThe special considerations for each component are listed below.\n\n14.2.1 datasets\nFolder path: ectddemo/m5/datasets/ectddemo/analysis/adam/datasets/.\n\nADaM data in .xpt format: created by SAS or R.\ndefine.xml: created by Pinnacle 21.\nADRG (Analysis Data Reviewer’s Guide)\n\n“Macro Programs” section: provide R and R package versions with a snapshot date.\nAppendix: provide step-by-step instructions for reviewers to reproduce the running environment and rerun analyses.\n\nARM (Analysis Results Metadata): provide the links between TLFs and analysis programs in tables.\n\n\n\n14.2.2 programs\nFolder path: ectddemo/m5/datasets/ectddemo/analysis/adam/programs/.\n\nr0pkgs.txt: contains all internally developed proprietary R packages.\nOther .txt files: each contains R code for a specific analysis.\n\n\n\n14.2.3 Notes\nTo verify if the submission package works, rerun all analyses following the instructions defined in ADRG.\nA few things need to be paid attention to in order to pass compliance checks:\n\nThe file names under programs/ should be in lower case letters (with no underscores or other special characters).\nThe .txt files should only contain ASCII characters. This can be verified by pkglite::verify_ascii()\nAll .docx files should be converted to PDF files for formal submission.\n\nNow you have a general idea about the relevant components of the submission package. We will prepare the proprietary R packages in the following sections."
  },
  {
    "objectID": "submission-package.html#practical-considerations-for-r-package-submissions",
    "href": "submission-package.html#practical-considerations-for-r-package-submissions",
    "title": "14  Submission package",
    "section": "14.3 Practical considerations for R package submissions",
    "text": "14.3 Practical considerations for R package submissions\nBefore we start, there are a few aspects to figure out in order to accurately identify the R packages for submission.\n\n14.3.1 Source location\nThere are a few common places to host R (source) packages:\n\nCRAN\nPublic Git repository\nPrivate Git repository (accessible externally)\nPrivate Git repository (inaccessible externally)\n\nFor R packages hosted on CRAN or a public Git repository, you probably do not need to submit them as part of the submission package, as the reviewers can install them directly by following the instructions in ADRG.\nFor R packages hosted in private repositories, to avoid any complications in infrastructure, authentication, and communication, it is often recommended to submit them as part of the submission package.\n\n\n14.3.2 Dependency locations\nR package dependency is another major factor to consider before preparing your proprietary R package for submission.\nFor dependencies available from CRAN or public Git repositories, you can declare them directly using the regular Imports and Suggests syntax or the remotes dependency syntax in the DESCRIPTION file.\nFor dependencies hosted in private Git repositories, you should pack them with the primary R package(s) you want to submit, as pkglite supports packing multiple R packages into a single text file; then restore and install them in the order they are packed.\n\n\n14.3.3 R version\nAlways use a consistent version of R for developing the TLFs and for submission. For example, you could enforce a rule to only use R x.y.z where z = 1, such as R 4.0.1 or R 4.1.1. This can be automatically checked using a startup script when the R project is opened.\n\n\n14.3.4 Package repo version\nAlways use the same snapshot package repo for developing the TLFs and for submission. Again, this can be checked in the project startup script, as discussed in Section 11.2.\n\n\n14.3.5 System environments\nIntroducing any extra external dependencies will likely increase the cost of qualification, validation, testing, and maintenance, especially under Windows. Therefore, it is recommended to keep the dependency chain simple, especially when involving compiled code (e.g., C, C++, Fortran)."
  },
  {
    "objectID": "submission-package.html#prepare-r-packages-for-submission",
    "href": "submission-package.html#prepare-r-packages-for-submission",
    "title": "14  Submission package",
    "section": "14.4 Prepare R packages for submission",
    "text": "14.4 Prepare R packages for submission\nTo prepare R packages for submission, one needs to pack the packages into text files, and then verify if the files only contain ASCII characters. With packed packages, one can unpack and install them from the text files, too.\n\n14.4.1 Pack\nLet’s pack the esubdemo package into a text file. Assume the source package path is esubdemo/. You should be able to pack the package with a single pipe:\n\nlibrary(\"pkglite\")\n\n\"esubdemo/\" %&gt;%\n  collate(file_ectd(), file_auto(\"inst\")) %&gt;%\n  pack(output = \"r0pkgs.txt\")\n\n\n\n\n\n\nOutput of pkglite::pack()\n\n\n\n\nLet’s open the generated text file:\n\nfile.edit(\"r0pkgs.txt\")\n\n\n\n\n\n\nPreview the generated text file\n\n\n\n\nWhat happened in the pipe? The function pkglite::collate() evaluates a specified scope of folders and files defined by a list of file specifications, and generates a file collection object. This file collection contains the metadata required to properly convert the files into text which is then used by pkglite::pack(). With this flow, you can define the scope of the R source package to be packed for submission in a flexible yet principled way.\nTo pack multiple R packages, simply feed multiple file collections as inputs:\n\npack(\n  \"/path/to/pkg1/\" %&gt;% collate(file_ectd()),\n  \"/path/to/pkg2/\" %&gt;% collate(file_ectd()),\n  output = \"r0pkgs.txt\"\n)\n\nThe R packages are always packed in the specified order and are always unpacked and installed in the same order. Therefore, make sure to pack the low-level dependencies first.\nFor more details on how to customize file specifications and operate on file collections, check out the vignette generate file specifications and curate file collections.\n\n\n14.4.2 Verify\nYou should always verify if the text file only contains ASCII characters:\n\nverify_ascii(\"r0pkgs.txt\")\n\nThis should give TRUE if the file only contains ASCII characters, or FALSE with the affected lines otherwise.\n\n\n14.4.3 Unpack\nOne can unpack and install the package from the text file, too. For example:\n\nunpack(\"r0pkgs.txt\", output = \"/tmp/\", install = TRUE)\n\nIf the test is successful, this command can be used in the ADRG instructions for restoring and installing the packed R package(s).\nYou can then proceed to move the file r0pkgs.txt to the folder ectddemo/m5/datasets/ectddemo/analysis/adam/programs/, or specify the output text file path above directly."
  },
  {
    "objectID": "submission-package.html#prepare-analysis-programs-for-submission",
    "href": "submission-package.html#prepare-analysis-programs-for-submission",
    "title": "14  Submission package",
    "section": "14.5 Prepare analysis programs for submission",
    "text": "14.5 Prepare analysis programs for submission\nBesides the R packages, we need to convert the R Markdown (.Rmd) files into .txt files and saved them in the programs/ folder. You can do this with knitr::purl():\n\ninput_path &lt;- \"esubdemo/vignettes/\"\noutput_path &lt;- \"ectddemo/m5/datasets/ectddemo/analysis/adam/programs/\"\n\nconvert_rmd &lt;- function(filename, input_dir, output_dir) {\n  knitr::purl(\n    file.path(input_dir, paste0(filename, \".Rmd\")),\n    output = file.path(output_dir, paste0(filename, \".txt\"))\n  )\n}\n\n\"tlf-01-disposition\" %&gt;% convert_rmd(input_path, output_path)\n\"tlf-02-population\" %&gt;% convert_rmd(input_path, output_path)\n\"tlf-03-baseline\" %&gt;% convert_rmd(input_path, output_path)\n\"tlf-04-efficacy\" %&gt;% convert_rmd(input_path, output_path)\n\"tlf-05-ae-summary\" %&gt;% convert_rmd(input_path, output_path)\n\"tlf-06-ae-spec\" %&gt;% convert_rmd(input_path, output_path)\n\nOptionally, you can add a header to the individual .txt files to explain the context and help the reviewers rerun the code. For example:\n# Note to Reviewer\n# To rerun the code below, please refer to the ADRG appendix.\n# After the required packages are installed,\n# the path variable needs to be defined by using the example code below.\n#\n# path = list(adam = \"/path/to/esub/analysis/adam/datasets\") # Modify to use actual location\n# path$outtable = path$outgraph = \".\" # Outputs saved to the current folder\nTo automate this process:\n\nheader &lt;- readLines(textConnection(\"# Note to Reviewer\n# To rerun the code below, please refer to the ADRG appendix.\n# After the required packages are installed,\n# the path variable needs to be defined by using the example code below.\n#\n# path = list(adam = \\\"/path/to/esub/analysis/adam/datasets\\\") # Modify to use actual location\n# path$outtable = path$outgraph = \\\".\\\" # Outputs saved to the current folder\"))\n\nappend_header &lt;- function(filename, output_dir, header) {\n  file &lt;- file.path(output_dir, paste0(filename, \".txt\"))\n  x &lt;- readLines(file)\n  y &lt;- c(header, \"\", x)\n  writeLines(y, con = file)\n  invisible(file)\n}\n\n\"tlf-01-disposition\" %&gt;% append_header(output_path, header)\n\"tlf-02-population\" %&gt;% append_header(output_path, header)\n\"tlf-03-baseline\" %&gt;% append_header(output_path, header)\n\"tlf-04-efficacy\" %&gt;% append_header(output_path, header)\n\"tlf-05-ae-summary\" %&gt;% append_header(output_path, header)\n\"tlf-06-ae-spec\" %&gt;% append_header(output_path, header)"
  },
  {
    "objectID": "submission-package.html#update-adrg",
    "href": "submission-package.html#update-adrg",
    "title": "14  Submission package",
    "section": "14.6 Update ADRG",
    "text": "14.6 Update ADRG\nAfter we converted the R packages and R Markdown files into the appropriate formats and verified that they can be restored and executed correctly, we need update the ADRG to provide guidelines on how to use them.\nSpecifically, we need to update two sections in ADRG.\nThe first section is “Macro Programs”, where R and R package versions with a snapshot date are provided. For example:\n7.x Macro Programs\n\nSubmitted R programs have [specific patterns] in filenames.\nAll internally developed R functions are saved in the r0pkgs.txt file.\nThe recommended steps to unpack these R functions for analysis output\nprograms are described in the Appendix.\n\nThe tables below contain the software version and instructions\nfor executing the R analysis output programs:\n\n\n\n\n\n\n\n\n\n\nProgram Name\nOutput Table\nTitle\n\n\n\n\ntlf-01-disposition.txt\nTable x.y.z\nDisposition of Patients\n\n\ntlf-02-population.txt\nTable x.y.z\nParticipants Accounting in Analysis Population (All Participants Randomized)\n\n\ntlf-03-baseline.txt\nTable x.y.z\nParticipant Baseline Characteristics (All Participants Randomized)\n\n\ntlf-04-efficacy.txt\nTable x.y.z\nANCOVA of Change from Baseline Glucose (mmol/L) at Week 24\nLOCF\nEfficacy Analysis Population\n\n\ntlf-05-ae-summary.txt\nTable x.y.z\nAnalysis of Adverse Event Summary (Safety Analysis Population)\n\n\ntlf-06-ae-spec.txt\nTable x.y.z\nAnalysis of Participants With Specific Adverse Events (Safety Analysis Population)\n\n\n\n\n\n\n\n\n\n\n\n\nOpen-Source R Analysis Package\nPackage Version\nAnalysis Package Description\n\n\n\n\npkglite\n0.2.0\nPrepare submission package\n\n\nhaven\n2.4.3\nRead SAS datasets\n\n\ndplyr\n1.0.7\nManipulate datasets\n\n\ntidyr\n1.1.3\nManipulate datasets\n\n\nemmeans\n1.6.2-1\nLeast-squares means estimation\n\n\nr2rtf\n0.3.0\nCreate RTF tables\n\n\n\n R package versions based on CRAN on 2021-08-06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProprietary R Analysis Package\nPackage Version\nAnalysis Package Description\n\n\n\n\nesubdemo\n0.1.0\nA demo package for analysis and reporting of clinical trials\n\n\n\n\n\n\n\nThe second section (Appendix) should include step-by-step instructions to reproduce the running environment and rerun analyses. For example:\nAppendix: Instructions to Execute Analysis Program in R\n\n1. Install R\n\nDownload and install R 4.1.1 for Windows from\nhttps://cran.r-project.org/bin/windows/base/old/4.1.1/R-4.1.1-win.exe\n\n2. Define working directory\n\nCreate a temporary working directory, for example, \"C:\\tempwork\".\nCopy all submitted R programs into the temporary folder.\nAll steps below should be executed in this working directory\nrepresented as \".\" in the example R code below.\n\n3. Specify R package repository\n\nThe R packages are based on CRAN at 2021-08-06. To install the exact\nR package versions used in this project, run the code below to set\nthe snapshot repository.\n\noptions(repos = \"https://packagemanager.posit.co/cran/2021-08-06\")\n\n4. Install open-source R packages\n\nIn the same R session, install the required packages by running the code below.\n\ninstall.packages(c(\"pkglite\", \"publicpkg1\", \"publicpkg2\"))\n\n5. Install proprietary R packages\n\nAll internal R packages are packed in the file r0pkgs.txt. In the same R session,\nrestore the package structures and install them by running the code below.\nAdjust the output path as needed to use a writable local directory.\n\npkglite::unpack(\"r0pkgs.txt\", output = \".\", install = TRUE)\n\n6. Update path to dataset and TLFs\n\nINPUT path: to rerun the analysis programs, define the path variable\n\n- Path for ADaM data: path$adam\n\nOUTPUT path: to save the analysis results, define the path variable\n\n- Path for output TLFs: path$output\n\nAll these paths need to be defined before executing the analysis program. For example:\n\npath = list(adam = \"/path/to/esub/analysis/adam/datasets/\") # Modify to use actual location\npath$outtable = path$outgraph = \".\" # Outputs saved to the current folder\n\n7. Execute analysis program\n\nTo reproduce the analysis results, rerun the following programs:\n\n- tlf-01-disposition.txt\n- tlf-02-population.txt\n- tlf-03-baseline.txt\n- tlf-04-efficacy.txt\n- tlf-05-ae-summary.txt\n- tlf-06-ae-spec.txt\nAn example ADRG following this template can be found in ectddemo."
  },
  {
    "objectID": "submission-package.html#update-arm",
    "href": "submission-package.html#update-arm",
    "title": "14  Submission package",
    "section": "14.7 Update ARM",
    "text": "14.7 Update ARM\nThe ARM (Analysis Results Metadata) should provide specific information related to R in two sections:\n\nSection 2: indicate the Programming Language;\nSection 3: document the details of the R programs listed in section 3.\n\nFor example, in ARM section 2, “Analysis Results Metadata Summary”:\n\nif (knitr::is_latex_output()) {\n  df4 %&gt;% kbl(format = \"latex\")\n}\n\nif (knitr::is_html_output()) {\n  df4 %&gt;%\n    kbl(format = \"html\") %&gt;%\n    kable_classic(full_width = FALSE, html_font = \"'Times New Roman', Times, serif\", font_size = 18) %&gt;%\n    column_spec(1, extra_css = \"border: 1px solid #000; text-align: center;\") %&gt;%\n    column_spec(2, extra_css = \"border: 1px solid #000; text-align: center;\") %&gt;%\n    column_spec(3, extra_css = \"border: 1px solid #000; text-align: center;\") %&gt;%\n    column_spec(4, extra_css = \"border: 1px solid #000; text-align: center;\") %&gt;%\n    column_spec(5, extra_css = \"border: 1px solid #000; text-align: center;\") %&gt;%\n    row_spec(0, background = \"#DFDFDF\", bold = TRUE, extra_css = \"border: 1px solid #000; text-align: center;\")\n}\n\n\n\n\nTable Reference\nTable Title\nProgramming Language\nProgram Name (programs)\nInput File Name / Analysis (datasets)\n\n\n\n\n[Ref. x.y.z: P001ZZZ9999: Table 1-1]\nDisposition of Patients\nR\ntlf-01-disposition.txt\nadsl.xpt\n\n\n...\n...\n...\n...\n...\n\n\n\n\n\n\n\nIn ARM section 3, “Analysis Results Metadata Details”:\n\n\n\n\n\nTable Reference: [Ref. x.y.z: P001ZZZ9999: Table 1-1]\n...\n\n\nAnalysis Result\n...\n\n\nAnalysis Parameters (s)\n...\n\n\nAnalysis Reason\n...\n\n\nAnalysis Purpose\n...\n\n\n...\n...\n\n\nProgramming Statements\n(R version 4.1.1), [P001ZZZ9999: programs-tlf-01-disposition]\n\n\n\n\n\n\n\n\n\n\n\nZhao, Yujie, Nan Xiao, Keaven Anderson, and Yilong Zhang. 2023. “Electronic Common Technical Document Submission with Analysis Using R.” Clinical Trials 20 (1): 89–92."
  },
  {
    "objectID": "submission-environment.html#prerequisites",
    "href": "submission-environment.html#prerequisites",
    "title": "15  Running environment",
    "section": "15.1 Prerequisites",
    "text": "15.1 Prerequisites\ncleanslate is an R package that offers a solution to create portable R environments.\n\n\n\n\n\n\nNote\n\n\n\nAs of Q4 2021, the cleanslate package used in this chapter is still under active development and validation. This chapter gives a preview of the planned APIs. They may change in the future.\n\n\nInstall cleanslate from CRAN (once available):\n\ninstall.packages(\"cleanslate\")\n\nOr from GitHub (once available):\n\nremotes::install_github(\"Merck/cleanslate\")"
  },
  {
    "objectID": "submission-environment.html#practical-considerations",
    "href": "submission-environment.html#practical-considerations",
    "title": "15  Running environment",
    "section": "15.2 Practical considerations",
    "text": "15.2 Practical considerations\nThe cleanslate package supports:\n\nCreating a project folder with project-specific context (.Rproj, .Rprofile, .Renviron)\nInstalling a specific version of R into the project folder\nInstalling a specific version of Rtools into the project folder\n\nAn essential feature of cleanslate is that it does not require administrator privileges to run R and Rtools installers. This makes it easier to deploy under enterprise settings and avoids security and portability concerns.\nAs many of the A&R deliverables are currently created, validated, and delivered under Windows, the primary focus is Windows at the moment, while the support for other platforms might be added in future versions."
  },
  {
    "objectID": "submission-environment.html#create-canonical-environments",
    "href": "submission-environment.html#create-canonical-environments",
    "title": "15  Running environment",
    "section": "15.3 Create canonical environments",
    "text": "15.3 Create canonical environments\nOne can create a running environment with “canonical” settings with a single function call to use_cleanslate():\n\ncleanslate::use_cleanslate(\n  \"C:/temp/\",\n  r_version = \"4.1.1\",\n  from = \"https://cran.r-project.org/\",\n  repo = \"https://packagemanager.posit.co/cran/2021-08-06\"\n)\n\nThis will\n\nCreate a project folder under C:/temp/ with a .Rproj file;\nDownload R 4.1.1 installer from CRAN, and install it into C:/temp/R/;\nNot install Rtools (by default, rtools_version = NULL);\nCreate a .Rprofile file under the project folder, set options(repos) to use the specified repo (a Posit Public Package Manager snapshot in this example), and give instruction to set the R binary path in RStudio IDE;\nCreate a .Renviron file under the project folder and set the library path to be the library of the project-specific R installation.\n\nAs a principle, one should always double-click the .Rproj file to open the project. This will ensure some sanity checks in the .Rprofile, such as whether the R and library are located within the project folder."
  },
  {
    "objectID": "submission-environment.html#create-tailored-environments",
    "href": "submission-environment.html#create-tailored-environments",
    "title": "15  Running environment",
    "section": "15.4 Create tailored environments",
    "text": "15.4 Create tailored environments\nTo create a more customized running environment, one can use the specific functions to tailor each aspect, for example:\n\nlibrary(\"cleanslate\")\n\n\"C:/temp/\" %&gt;%\n  use_project() %&gt;%\n  use_rprofile() %&gt;%\n  use_renviron() %&gt;%\n  use_r_version(version = \"4.1.1\") %&gt;%\n  use_rtools(version = \"rtools40\")\n\nThe project context functions (use_project(), use_rprofile(), use_renviron) support custom templates using brew.\nThe use_r_*() functions have variations that serve as shortcuts to use R versions defined by release lifecycles, for example, use_r_release(), use_r_oldrel(), and use_r_devel(). Note that to ensure better reproducibility, one should still use use_r_version() as the release, oldrel, and devel versions will shift as time goes by.\nThe helper functions version_*() and snapshot_*() can assist you in determining specific versions of R and Rtools that are currently available, besides generating and verifying the snapshot repo links."
  },
  {
    "objectID": "submission-environment.html#update-adrg",
    "href": "submission-environment.html#update-adrg",
    "title": "15  Running environment",
    "section": "15.5 Update ADRG",
    "text": "15.5 Update ADRG\nIf you use cleanslate, remember to update the ADRG instructions for executing the analysis programs in R. Mostly, this can simplify the first three steps on creating a project, installing a specific version of R, and configuring the package repo location. For example:\nAppendix: Instructions to Execute Analysis Program in R\n\n1. Setup R environment\n\nOpen the existing R, install the required packages by running the code below.\n\ninstall.packages(\"cleanslate\")\n\nCreate a temporary working directory, for example, \"C:\\tempwork\".\nCopy all submitted R programs into the temporary folder.\nIn the same R session, run the code below to create a project\nwith a portable R environment.\n\ncleanslate::use_cleanslate(\n  \"C:/temp/\",\n  r_version = \"4.1.1\",\n  from = \"https://cran.r-project.org/\",\n  repo = \"https://packagemanager.posit.co/cran/2021-08-06\"\n)\n\n2. Open the project\n\nGo to the working directory created above, double click the .Rproj file\nto open the project in RStudio IDE. Follow the instructions to select the\nproject-specific R version, then restart RStudio IDE. If successful,\nthe R version and package repo should be printed as defined above.\n\n3. Install open-source R packages\n\nIn the new R session, install the required packages by running the code below.\n\ninstall.packages(c(\"pkglite\", \"publicpkg1\", \"publicpkg2\"))\n\n4. Install proprietary R packages\n\nAll internal R packages are packed in the file r0pkgs.txt. In the same R session,\nrestore the package structures and install them by running the code below.\nAdjust the output path as needed to use a writable local directory.\n\npkglite::unpack(\"r0pkgs.txt\", output = \".\", install = TRUE)\n\n5. Update path to dataset and TLFs\n\nINPUT path: to rerun the analysis programs, define the path variable\n\n- Path for ADaM data: path$adam\n\nOUTPUT path: to save the analysis results, define the path variable\n\n- Path for output TLFs: path$output\n\nAll these paths need to be defined before executing the analysis program. For example:\n\npath = list(adam = \"/path/to/esub/analysis/adam/datasets/\") # Modify to use actual location\npath$outtable = path$outgraph = \".\" # Outputs saved to the current folder\n\n6. Execute analysis program\n\nTo reproduce the analysis results, rerun the following programs:\n\n- tlf-01-disposition.txt\n- tlf-02-population.txt\n- tlf-03-baseline.txt\n- tlf-04-efficacy.txt\n- tlf-05-ae-summary.txt\n- tlf-06-ae-spec.txt"
  },
  {
    "objectID": "submission-environment.html#rstudio-addin",
    "href": "submission-environment.html#rstudio-addin",
    "title": "15  Running environment",
    "section": "15.6 RStudio addin",
    "text": "15.6 RStudio addin\nTo make it convenient to use cleanslate in experiments, one can also use its RStudio IDE addin. After cleanslate is installed, click Addins -&gt; cleanslate -&gt; Create portable R environment in RStudio IDE, or call cleanslate:::create_env_addin() to open it.\n\n\n\n\n\ncleanslate RStudio addin\n\n\n\n\nThe addin provides a wizard-like interface to help create the environment with the most important options, yet with less flexibility compared to the functional API demonstrated above."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Fitzpatrick, Brian, and Ben Collins-Sussman. 2012. Team Geek: A\nSoftware Developer’s Guide to Working Well with Others. O’Reilly\nMedia.\n\n\nGinnaram, Madhusudhan, Simiao Ye, Yalin Zhu, and Yilong Zhang. 2021.\n“A Process to Validate Internal Developed R Package\nUnder Regulatory Environment.” PharmaSUG.\n\n\nMartin, Robert C, James Grenning, and Simon Brown. 2018. Clean\nArchitecture: A Craftsman’s Guide to Software Structure and Design.\nPrentice Hall.\n\n\nMarwick, Ben, Carl Boettiger, and Lincoln Mullen. 2018. “Packaging\nData Analytical Work Reproducibly Using R (and\nFriends).” The American Statistician 72 (1): 80–88.\n\n\nNüst, Daniel, Dirk Eddelbuettel, Dom Bennett, Robrecht Cannoodt, Dav\nClark, Gergely Daróczi, Mark Edmondson, et al. 2020. “The\nRockerverse: Packages and Applications for Containerisation\nwith R.” The R Journal 12 (1):\n437–61.\n\n\nWickham, Hadley, and Jennifer Bryan. 2023. R Packages. O’Reilly\nMedia, Inc.\n\n\nWu, Peikun, Uday Preetham Palukuru, Yiwen Luo, Sarad Nepal, and Yilong\nZhang. 2021. “Analysis and Reporting in Regulated Clinical Trial\nEnvironment Using R.” PharmaSUG.\n\n\nZhao, Yujie, Nan Xiao, Keaven Anderson, and Yilong Zhang. 2023.\n“Electronic Common Technical Document Submission with Analysis\nUsing R.” Clinical Trials 20 (1): 89–92."
  }
]